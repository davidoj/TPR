
@misc{hacking_emergence_2006,
	title = {The {Emergence} of {Probability} by {Ian} {Hacking}},
	url = {/core/books/emergence-of-probability/9852017A380C63DA30886D25B80336A7},
	abstract = {Cambridge Core - Philosophy of Science - The Emergence of Probability -  by Ian Hacking},
	language = {en},
	urldate = {2019-01-30},
	journal = {Cambridge Core},
	author = {Hacking, Ian},
	month = jul,
	year = {2006},
	doi = {10.1017/CBO9780511817557},
	file = {Snapshot:C\:\\Users\\david\\Zotero\\storage\\LVYCIHPC\\9852017A380C63DA30886D25B80336A7.html:text/html}
}

@book{von_neumann_theory_1944,
	address = {Princeton, NJ, US},
	series = {Theory of games and economic behavior},
	title = {Theory of games and economic behavior},
	abstract = {The authors analyze some fundamental questions of economic theory in terms of a mathematical theory of games. The common elements of economic behavior and such factors as strategy in games are presented, and the interrelated concepts are analyzed around the more or less central problem of utility. The book is divided into 12 chapters, the first being a formulation of the economic problem, presenting the objectives of the system used, the notion of utility, and a description of the structure of the authors' theory. The second chapter is a general formal description of games of strategy, and chapters 3-8 treat particular classifications of games. In chapter 9, the authors discuss the composition and decomposition of games. Chapter 10 is on simple games, and chapter 11 on general non-zero-sum games. (These are games in which the sum of all payments received by all players is not zero. Thus such games involve production or destruction of goods and are more closely analogous to general social and economic situations than zero-sum games.) The concluding chapter presents a generalization of the concept of utility and the discussion of an example. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {Princeton University Press},
	author = {Von Neumann, J. and Morgenstern, O.},
	year = {1944},
	file = {Snapshot:C\:\\Users\\david\\Zotero\\storage\\CTQLIQWX\\1945-00500-000.html:text/html}
}

@article{schoemaker_expected_1982,
	title = {The {Expected} {Utility} {Model}: {Its} {Variants}, {Purposes}, {Evidence} and {Limitations}},
	volume = {20},
	issn = {0022-0515},
	shorttitle = {The {Expected} {Utility} {Model}},
	url = {https://www.jstor.org/stable/2724488},
	number = {2},
	urldate = {2019-01-31},
	journal = {Journal of Economic Literature},
	author = {Schoemaker, Paul J. H.},
	year = {1982},
	pages = {529--563}
}

@article{savage_theory_1951,
	title = {The theory of statistical decision},
	volume = {46},
	issn = {1537-274X(Electronic),0162-1459(Print)},
	doi = {10.2307/2280094},
	abstract = {Abraham Wald's recent book, Statistical Decision Functions, presents a new theory of the foundations of statistics. The vigorous exploration of this theory was begun by Professor Wald five or six years ago and is being continued under his leadership. The critical and philosophical remarks in this exposition may not accurately represent the views of Professor Wald, for both in writing and lecturing, he prefers to be rather non-committal on such points. Wald's report on the current state of the theory of statistical decision is of great scholarly value, and its possible influence for the good on statistics, through the enthusiastic few who are able to study it, is inestimable. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Journal of the American Statistical Association},
	author = {Savage, L. J.},
	year = {1951},
	pages = {55--67},
	file = {Snapshot:C\:\\Users\\david\\Zotero\\storage\\CII4AC78\\1951-06617-001.html:text/html}
}

@book{shalev-shwartz_understanding_2014,
	title = {Understanding {Machine} {Learning}: {From} {Theory} to {Algorithms}},
	isbn = {978-1-139-95274-3},
	shorttitle = {Understanding {Machine} {Learning}},
	abstract = {Machine learning is one of the fastest growing areas of computer science, with far-reaching applications. The aim of this textbook is to introduce machine learning, and the algorithmic paradigms it offers, in a principled way. The book provides a theoretical account of the fundamentals underlying machine learning and the mathematical derivations that transform these principles into practical algorithms. Following a presentation of the basics, the book covers a wide array of central topics unaddressed by previous textbooks. These include a discussion of the computational complexity of learning and the concepts of convexity and stability; important algorithmic paradigms including stochastic gradient descent, neural networks, and structured output learning; and emerging theoretical concepts such as the PAC-Bayes approach and compression-based bounds. Designed for advanced undergraduates or beginning graduates, the text makes the fundamentals and algorithms of machine learning accessible to students and non-expert readers in statistics, computer science, mathematics and engineering.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Shalev-Shwartz, Shai and Ben-David, Shai},
	month = may,
	year = {2014},
	note = {Google-Books-ID: Hf6QAwAAQBAJ},
	keywords = {Computers / Computer Vision \& Pattern Recognition, Computers / Optical Data Processing}
}

@article{jeffrey_logic_1981,
	title = {The logic of decision defended},
	volume = {48},
	issn = {1573-0964},
	url = {https://doi.org/10.1007/BF01063989},
	doi = {10.1007/BF01063989},
	abstract = {The approach to decision theory floated in my 1965 book is reviewed (I), challenged in various related ways (II–V) and defended, firstad hoc (II–IV) and then by a general argument of Ellery Ells's (VI). Finally, causal decision theory (in a version sketched in VII) is exhibited as a special case of my 1965 theory, according to the Eellsian argument.},
	language = {en},
	number = {3},
	urldate = {2018-11-19},
	journal = {Synthese},
	author = {Jeffrey, Richard},
	month = sep,
	year = {1981},
	keywords = {Causal Decision, Causal Decision Theory, Decision Theory, General Argument},
	pages = {473--492},
	file = {Springer Full Text PDF:/home/users/u4533535/Zotero/storage/ZXMJH69T/Jeffrey - 1981 - The logic of decision defended.pdf:application/pdf}
}

@misc{horgan_counterfactuals_1981,
	title = {Counterfactuals and {Newcomb}'s {Problem}},
	url = {https://www.pdcnet.org/pdc/bvdb.nsf/purchase?openform&fp=jphil&id=jphil_1981_0078_0006_0331_0356},
	urldate = {2019-01-08},
	journal = {The Journal of Philosophy},
	author = {Horgan, Terence},
	month = jun,
	year = {1981},
	doi = {10.2307/2026128},
	file = {Snapshot:C\:\\Users\\david\\Zotero\\storage\\YNXJ7XHN\\jphil_1981_0078_0006_0331_0356.html:text/html}
}

@book{ogata_discrete-time_1995,
	address = {Englewood Cliffs, N.J},
	edition = {2 edition},
	title = {Discrete-{Time} {Control} {Systems}},
	isbn = {978-0-13-034281-2},
	abstract = {The new edition of this comprehensive digital controls book integrates MATLAB throughout the book. The book has also increased inflexibility and reader friendliness through the streamlining of coverage in Chapters 6 \& 7 (controllability, pole placement and observability, and optimal control). The previous edition ISBN is: 0-13-216102-8.},
	language = {English},
	publisher = {Pearson},
	author = {Ogata, Katsuhiko},
	month = jan,
	year = {1995}
}

@book{nise_control_2010,
	address = {Hoboken, NJ},
	edition = {6th Edition Binder Ready Version edition},
	title = {Control {Systems} {Engineering}},
	isbn = {978-0-470-91769-5},
	abstract = {This text is an unbound, binder-ready edition. Highly regarded for its accessible writing and practical case studies, Control Systems Engineering is the most widely adopted textbook for this core course in Mechanical and Electrical engineering programs. This new sixth edition has been revised and updated with 20\% new problems and greater emphasis on computer-aided design.},
	language = {English},
	publisher = {Wiley},
	author = {Nise, Norman S.},
	month = dec,
	year = {2010}
}

@book{stengel_stochastic_1986,
	title = {Stochastic {Optimal} {Control}: {Theory} and {Applications}},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Stengel, Robert},
	year = {1986}
}

@book{kokotovic_foundations_1991,
	title = {Foundations of adaptive control},
	isbn = {978-3-540-54020-5},
	abstract = {The 1990 Grainger Lectures delivered at the University of Illinois, Urbana-Champaign, September 28 - October 1, 1990 were devoted to a critical reexamination of the foundations of adaptive control. In this volume the lectures are expanded by most recent developments and solutions for some long-standing open problems. Concepts and approaches presented are both novel and of fundamental importance for adaptive control research in the 1990s. The papers in Part I present unifications, reappraisals and new results on tunability, convergence and robustness of adaptive linear control, whereas the papers in Part II formulate new problems in adaptive control of nonlinear systems and solve them without any linear constraints imposed on the nonlinearities.},
	language = {en},
	publisher = {Springer-Verlag},
	author = {Kokotović, Petar V.},
	year = {1991},
	note = {Google-Books-ID: hwBFAQAAIAAJ},
	keywords = {Mathematics / Linear \& Nonlinear Programming, Technology \& Engineering / Electrical, Technology \& Engineering / Robotics, Adaptive control systems, Mathematics / Applied, Technology \& Engineering / Engineering (General)}
}

@misc{barto_reinforcement_1998,
	type = {text},
	title = {Reinforcement {Learning}: {An} {Introduction}},
	shorttitle = {Reinforcement {Learning}},
	url = {http://jmvidal.cse.sc.edu/lib/sutton98a.html},
	language = {en},
	urldate = {2018-04-30},
	author = {Barto, Richard S. Sutton {and} Andrew G.},
	year = {1998},
	file = {Snapshot:/home/users/u4533535/Zotero/storage/U97TUHRH/sutton98a.html:text/html}
}

@book{wald1950statistical,
  title={Statistical decision functions.},
  author={Wald, Abraham},
  year={1950},
  publisher={Wiley}
}


@inproceedings{jaakkola_reinforcement_1994,
	address = {Cambridge, MA, USA},
	series = {{NIPS}'94},
	title = {Reinforcement {Learning} {Algorithm} for {Partially} {Observable} {Markov} {Decision} {Problems}},
	url = {http://dl.acm.org/citation.cfm?id=2998687.2998730},
	abstract = {Increasing attention has been paid to reinforcement learning algorithms in recent years, partly due to successes in the theoretical analysis of their behavior in Markov environments. If the Markov assumption is removed, however, neither generally the algorithms nor the analyses continue to be usable. We propose and analyze a new learning algorithm to solve a certain class of non-Markov decision problems. Our algorithm applies to problems in which the environment is Markov, but the learner has restricted access to state information. The algorithm involves a Monte-Carlo policy evaluation combined with a policy improvement method that is similar to that of Markov decision problems and is guaranteed to converge to a local maximum. The algorithm operates in the space of stochastic policies, a space which can yield a policy that performs considerably better than any deterministic policy. Although the space of stochastic policies is continuous--even for a discrete action space--our algorithm is computationally tractable.},
	urldate = {2019-02-01},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Jaakkola, Tommi and Singh, Satinder P. and Jordan, Michael I.},
	year = {1994},
	pages = {345--352}
}

@article{monahan_state_1982,
	title = {State of the {Art}—{A} {Survey} of {Partially} {Observable} {Markov} {Decision} {Processes}: {Theory}, {Models}, and {Algorithms}},
	volume = {28},
	issn = {0025-1909},
	shorttitle = {State of the {Art}—{A} {Survey} of {Partially} {Observable} {Markov} {Decision} {Processes}},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.28.1.1},
	doi = {10.1287/mnsc.28.1.1},
	abstract = {This paper surveys models and algorithms dealing with partially observable Markov decision processes. A partially observable Markov decision process (POMDP) is a generalization of a Markov decision process which permits uncertainty regarding the state of a Markov process and allows for state information acquisition. A general framework for finite state and action POMDP's is presented. Next, there is a brief discussion of the development of POMDP's and their relationship with other decision processes. A wide range of models in such areas as quality control, machine maintenance, internal auditing, learning, and optimal stopping are discussed within the POMDP-framework. Lastly, algorithms for computing optimal solutions to POMDP's are presented.},
	number = {1},
	urldate = {2019-02-01},
	journal = {Management Science},
	author = {Monahan, George E.},
	month = jan,
	year = {1982},
	pages = {1--16},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/CQPV3JKJ/Monahan - 1982 - State of the Art—A Survey of Partially Observable .pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/K8WFR76D/mnsc.28.1.html:text/html}
}

@article{cartwright_causation:_2004,
	title = {Causation: {One} {Word}, {Many} {Things}},
	volume = {71},
	issn = {0031-8248},
	shorttitle = {Causation},
	url = {https://www.jstor.org/stable/10.1086/426771},
	doi = {10.1086/426771},
	abstract = {We currently have on offer a variety of different theories of causation. Many are strikingly good, providing detailed and plausible treatments of exemplary cases; and all suffer from clear counterexamples. I argue that, contra Hume and Kant, this is because causation is not a single, monolithic concept. There are different kinds of causal relations imbedded in different kinds of systems, readily described using thick causal concepts. Our causal theories pick out important and useful structures that fit some familiar cases—cases we discover and ones we devise to fit.},
	number = {5},
	urldate = {2018-12-17},
	journal = {Philosophy of Science},
	author = {Cartwright, Nancy},
	year = {2004},
	pages = {805--819},
	file = {JSTOR Full Text PDF:/home/users/u4533535/Zotero/storage/NCSVX2W3/Cartwright - 2004 - Causation One Word, Many Things.pdf:application/pdf}
}
@article{rubenstein_causal_2017,
	title = {Causal {Consistency} of {Structural} {Equation} {Models}},
	url = {http://arxiv.org/abs/1707.00819},
	abstract = {Complex systems can be modelled at various levels of detail. Ideally, causal models of the same system should be consistent with one another in the sense that they agree in their predictions of the effects of interventions. We formalise this notion of consistency in the case of Structural Equation Models (SEMs) by introducing exact transformations between SEMs. This provides a general language to consider, for instance, the different levels of description in the following three scenarios: (a) models with large numbers of variables versus models in which the `irrelevant' or unobservable variables have been marginalised out; (b) micro-level models versus macro-level models in which the macro-variables are aggregate features of the micro-variables; (c) dynamical time series models versus models of their stationary behaviour. Our analysis stresses the importance of well specified interventions in the causal modelling process and sheds light on the interpretation of cyclic SEMs.},
	urldate = {2019-02-04},
	journal = {arXiv:1707.00819 [cs, stat]},
	author = {Rubenstein, Paul K. and Weichwald, Sebastian and Bongers, Stephan and Mooij, Joris M. and Janzing, Dominik and Grosse-Wentrup, Moritz and Schölkopf, Bernhard},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.00819},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Machine Learning, Statistics - Methodology, Computer Science - Machine Learning},
	annote = {Comment: equal contribution between Rubenstein and Weichwald; accepted manuscript}
}

@article{gelman_causality_2011,
	title = {Causality and {Statistical} {Learning}},
	volume = {117},
	issn = {0002-9602},
	url = {https://www.journals.uchicago.edu/doi/full/10.1086/662659},
	doi = {10.1086/662659},
	number = {3},
	urldate = {2019-02-04},
	journal = {American Journal of Sociology},
	author = {Gelman, Andrew},
	month = nov,
	year = {2011},
	pages = {955--966},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/GYLWK5IV/Gelman - 2011 - Causality and Statistical Learning.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/JKCUWWYJ/662659.html:text/html}
}

@article{haavelmo1943statistical,
  title={The statistical implications of a system of simultaneous equations},
  author={Haavelmo, Trygve},
  journal={Econometrica, Journal of the Econometric Society},
  pages={1--12},
  year={1943},
  publisher={JSTOR}
}

@techreport{heckman_structural_2005,
	type = {Working {Paper}},
	title = {Structural {Equations}, {Treatment} {Effects} and {Econometric} {Policy} {Evaluation}},
	url = {http://www.nber.org/papers/w11259},
	abstract = {This paper uses the marginal treatment effect (MTE) to unify the nonparametric literature on treatment effects with the econometric literature on structural estimation using a nonparametric analog of a policy invariant parameter; to generate a variety of treatment effects from a common semiparametric functional form; to organize the literature on alternative estimators; and to explore what policy questions commonly used estimators in the treatment effect literature answer. A fundamental asymmetry intrinsic to the method of instrumental variables is noted. Recent advances in IV estimation allow for heterogeneity in responses but not in choices, and the method breaks down when both choice and response equations are heterogeneous in a general way.},
	number = {11259},
	urldate = {2018-02-06},
	institution = {National Bureau of Economic Research},
	author = {Heckman, James J. and Vytlacil, Edward},
	month = apr,
	year = {2005},
	doi = {10.3386/w11259},
	file = {NBER Full Text PDF:C\:\\Users\\david\\Zotero\\storage\\JJDUJQ6S\\Heckman and Vytlacil - 2005 - Structural Equations, Treatment Effects and Econom.pdf:application/pdf}
}

@inproceedings{itani2010structure,
  title={Structure learning in causal cyclic networks},
  author={Itani, Sleiman and Ohannessian, Mesrob and Sachs, Karen and Nolan, Garry P and Dahleh, Munther A},
  booktitle={Causality: Objectives and Assessment},
  pages={165--176},
  year={2010}
}

@article{chin_commentary:_1998,
	title = {Commentary: {Issues} and {Opinion} on {Structural} {Equation} {Modeling}},
	volume = {22},
	issn = {0276-7783},
	shorttitle = {Commentary},
	url = {https://www.jstor.org/stable/249674},
	number = {1},
	urldate = {2019-02-06},
	journal = {MIS Quarterly},
	author = {Chin, Wynne W.},
	year = {1998},
	pages = {vii--xvi}
}

@inproceedings{bareinboim_local_2012,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Local {Characterizations} of {Causal} {Bayesian} {Networks}},
	isbn = {978-3-642-29449-5},
	abstract = {The standard definition of causal Bayesian networks (CBNs) invokes a global condition according to which the distribution resulting from any intervention can be decomposed into a truncated product dictated by its respective mutilated subgraph. We analyze alternative formulations which emphasizes local aspects of the causal process and can serve therefore as more meaningful criteria for coherence testing and network construction. We first examine a definition based on “modularity” and prove its equivalence to the global definition. We then introduce two new definitions, the first interprets the missing edges in the graph, and the second interprets “zero direct effect” (i.e., ceteris paribus). We show that these formulations are equivalent but carry different semantic content.},
	language = {en},
	booktitle = {Graph {Structures} for {Knowledge} {Representation} and {Reasoning}},
	publisher = {Springer Berlin Heidelberg},
	author = {Bareinboim, Elias and Brito, Carlos and Pearl, Judea},
	editor = {Croitoru, Madalina and Rudolph, Sebastian and Wilson, Nic and Howse, John and Corby, Olivier},
	year = {2012},
	keywords = {Causal Information, Directed Acyclic Graph, Interventional Distribution, Manipulate Variable, Probabilistic Interpretation},
	pages = {1--17},
	file = {Springer Full Text PDF:/home/users/u4533535/Zotero/storage/6F7JA6K9/Bareinboim et al. - 2012 - Local Characterizations of Causal Bayesian Network.pdf:application/pdf}
}

@inproceedings{eaton_exact_2007,
	title = {Exact {Bayesian} structure learning from uncertain interventions},
	url = {http://proceedings.mlr.press/v2/eaton07a.html},
	abstract = {We show how to apply the dynamic programming algorithm of Koivisto and Sood [KS04, Koi06], which computes the exact posterior marginal edge probabilities p(G\_ij = 1{\textbar}D) of a DAG G given data D, to t...},
	language = {en},
	urldate = {2019-02-06},
	booktitle = {Artificial {Intelligence} and {Statistics}},
	author = {Eaton, Daniel and Murphy, Kevin},
	month = mar,
	year = {2007},
	pages = {107--114},
	file = {Full Text PDF:C\:\\Users\\david\\Zotero\\storage\\V2IW3NPA\\Eaton and Murphy - 2007 - Exact Bayesian structure learning from uncertain i.pdf:application/pdf;Snapshot:C\:\\Users\\david\\Zotero\\storage\\U5AW53TL\\eaton07a.html:text/html}
}

@article{hauser_characterization_2012,
	title = {Characterization and {Greedy} {Learning} of {Interventional} {Markov} {Equivalence} {Classes} of {Directed} {Acyclic} {Graphs}},
	volume = {13},
	issn = {ISSN 1533-7928},
	url = {http://www.jmlr.org/papers/v13/hauser12a.html},
	number = {Aug},
	urldate = {2018-06-06},
	journal = {Journal of Machine Learning Research},
	author = {Hauser, Alain and Bühlmann, Peter},
	year = {2012},
	pages = {2409--2464},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/AR23G9FQ/Hauser and Bühlmann - 2012 - Characterization and Greedy Learning of Interventi.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/25U334TM/hauser12a.html:text/html}
}

@article{mooij_joint_2016,
	title = {Joint {Causal} {Inference} from {Multiple} {Contexts}},
	url = {http://arxiv.org/abs/1611.10351},
	abstract = {The gold standard for discovering causal relations is by means of experimentation. Over the last decades, alternative methods have been proposed that can infer causal relations between variables from certain statistical patterns in purely observational data. We introduce Joint Causal Inference (JCI), a novel approach to causal discovery from multiple data sets that elegantly unifies both approaches. JCI is a causal modeling approach rather than a specific algorithm, and it can be used in combination with any causal discovery algorithm that can take into account certain background knowledge. The main idea is to reduce causal discovery from multiple datasets originating from different contexts (e.g., different experimental conditions) to causal discovery from a single pooled dataset by adding a set of auxiliary context variables. JCI offers the following features: it deals with several different types of interventions in a unified fashion, it can learn intervention targets, it pools data across different datasets which improves the statistical power of independence tests, and by exploiting differences in distribution between contexts it improves on the accuracy and identifiability of the predicted causal relations. We evaluate the approach on flow cytometry data.},
	urldate = {2018-10-29},
	journal = {arXiv:1611.10351 [cs, stat]},
	author = {Mooij, Joris M. and Magliacane, Sara and Claassen, Tom},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.10351},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Machine Learning, Computer Science - Machine Learning},
	annote = {Comment: Major revision, will be resubmitted to JMLR},
	file = {arXiv\:1611.10351 PDF:C\:\\Users\\david\\Zotero\\storage\\B52QEIRW\\Mooij et al. - 2016 - Joint Causal Inference from Multiple Contexts.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\david\\Zotero\\storage\\4PZ7MHD9\\1611.html:text/html}
}

@article{yang_characterizing_2018,
	title = {Characterizing and {Learning} {Equivalence} {Classes} of {Causal} {DAGs} under {Interventions}},
	url = {http://arxiv.org/abs/1802.06310},
	abstract = {We consider the problem of learning causal DAGs in the setting where both observational and interventional data is available. This setting is common in biology, where gene regulatory networks can be intervened on using chemical reagents or gene deletions. Hauser and B{\textbackslash}"uhlmann (2012) previously characterized the identifiability of causal DAGs under perfect interventions, which eliminate dependencies between targeted variables and their direct causes. In this paper, we extend these identifiability results to general interventions, which may modify the dependencies between targeted variables and their causes without eliminating them. We define and characterize the interventional Markov equivalence class that can be identified from general (not necessarily perfect) intervention experiments. We also propose the first provably consistent algorithm for learning DAGs in this setting and evaluate our algorithm on simulated and biological datasets.},
	urldate = {2018-06-06},
	journal = {arXiv:1802.06310 [math, stat]},
	author = {Yang, Karren D. and Katcoff, Abigail and Uhler, Caroline},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.06310},
	keywords = {Mathematics - Statistics Theory, Statistics - Applications, Statistics - Methodology},
	annote = {Comment: 18 pages, 7 figures},
	file = {arXiv\:1802.06310 PDF:/home/users/u4533535/Zotero/storage/QYBLHGF6/Yang et al. - 2018 - Characterizing and Learning Equivalence Classes of.pdf:application/pdf;arXiv.org Snapshot:/home/users/u4533535/Zotero/storage/9XLAKWAE/1802.html:text/html}
}

@article{evans_margins_2015,
	title = {Margins of discrete {Bayesian} networks},
	url = {http://arxiv.org/abs/1501.02103},
	abstract = {Bayesian network models with latent variables are widely used in statistics and machine learning. In this paper we provide a complete algebraic characterization of Bayesian network models with latent variables when the observed variables are discrete and no assumption is made about the state-space of the latent variables. We show that it is algebraically equivalent to the so-called nested Markov model, meaning that the two are the same up to inequality constraints on the joint probabilities. In particular these two models have the same dimension. The nested Markov model is therefore the best possible description of the latent variable model that avoids consideration of inequalities, which are extremely complicated in general. A consequence of this is that the constraint finding algorithm of Tian and Pearl (UAI 2002, pp519-527) is complete for finding equality constraints. Latent variable models suffer from difficulties of unidentifiable parameters and non-regular asymptotics; in contrast the nested Markov model is fully identifiable, represents a curved exponential family of known dimension, and can easily be fitted using an explicit parameterization.},
	urldate = {2018-02-20},
	journal = {arXiv:1501.02103 [math, stat]},
	author = {Evans, Robin J.},
	month = jan,
	year = {2015},
	note = {arXiv: 1501.02103},
	keywords = {Mathematics - Statistics Theory, Statistics - Machine Learning},
	annote = {Comment: 41 pages},
	annote = {Shows that nested markov models have the same dimension as marginal DAGs, which model DAGs with hidden variables. Nested markov models furthermore respect all equality constraints of mDAGs, though mDAGs might respect further inequality constraints; Tian and Pearl (related) show how to derive these equality constraints},
	file = {arXiv\:1501.02103 PDF:/home/users/u4533535/Zotero/storage/L9ALWTEB/Evans - 2015 - Margins of discrete Bayesian networks.pdf:application/pdf;arXiv.org Snapshot:/home/users/u4533535/Zotero/storage/ZAXBMMS3/1501.html:text/html}
}

@article{kang_inequality_2012,
	title = {Inequality {Constraints} in {Causal} {Models} with {Hidden} {Variables}},
	url = {http://arxiv.org/abs/1206.6829},
	abstract = {We present a class of inequality constraints on the set of distributions induced by local interventions on variables governed by a causal Bayesian network, in which some of the variables remain unmeasured. We derive bounds on causal effects that are not directly measured in randomized experiments. We derive instrumental inequality type of constraints on nonexperimental distributions. The results have applications in testing causal models with observational or experimental data.},
	urldate = {2018-02-20},
	journal = {arXiv:1206.6829 [cs, stat]},
	author = {Kang, Changsung and Tian, Jin},
	month = jun,
	year = {2012},
	note = {arXiv: 1206.6829},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Methodology},
	annote = {Comment: Appears in Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence (UAI2006)},
	file = {arXiv\:1206.6829 PDF:/home/users/u4533535/Zotero/storage/TBWYF3KN/Kang and Tian - 2012 - Inequality Constraints in Causal Models with Hidde.pdf:application/pdf;arXiv.org Snapshot:/home/users/u4533535/Zotero/storage/PNZ4JUK5/1206.html:text/html}
}

@article{angrist_identification_1996,
	title = {Identification of {Causal} {Effects} {Using} {Instrumental} {Variables}},
	volume = {91},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1996.10476902},
	doi = {10.1080/01621459.1996.10476902},
	abstract = {We outline a framework for causal inference in settings where assignment to a binary treatment is ignorable, but compliance with the assignment is not perfect so that the receipt of treatment is nonignorable. To address the problems associated with comparing subjects by the ignorable assignment—an “intention-to-treat analysis”—we make use of instrumental variables, which have long been used by economists in the context of regression models with constant treatment effects. We show that the instrumental variables (IV) estimand can be embedded within the Rubin Causal Model (RCM) and that under some simple and easily interpretable assumptions, the IV estimand is the average causal effect for a subgroup of units, the compliers. Without these assumptions, the IV estimand is simply the ratio of intention-to-treat causal estimands with no interpretation as an average causal effect. The advantages of embedding the IV approach in the RCM are that it clarifies the nature of critical assumptions needed for a causal interpretation, and moreover allows us to consider sensitivity of the results to deviations from key assumptions in a straightforward manner. We apply our analysis to estimate the effect of veteran status in the Vietnam era on mortality, using the lottery number that assigned priority for the draft as an instrument, and we use our results to investigate the sensitivity of the conclusions to critical assumptions.},
	number = {434},
	urldate = {2018-03-05},
	journal = {Journal of the American Statistical Association},
	author = {Angrist, Joshua D. and Imbens, Guido W. and Rubin, Donald B.},
	month = jun,
	year = {1996},
	keywords = {Compliers, Intention-to-treat analysis, Local average treatment effect, Noncompliance, Nonignorable treatment assignment, Rubin-Causal-Model, Structural equation models},
	pages = {444--455},
	file = {Snapshot:C\:\\Users\\david\\Zotero\\storage\\T7KVM73C\\01621459.1996.html:text/html}
}

@book{jeffrey_logic_1990,
	title = {The {Logic} of {Decision}},
	isbn = {978-0-226-39582-1},
	abstract = {"[This book] proposes new foundations for the Bayesian principle of rational action, and goes on to develop a new logic of desirability and probabtility."—Frederic Schick, Journal of Philosophy},
	language = {en},
	publisher = {University of Chicago Press},
	author = {Jeffrey, Richard C.},
	month = jul,
	year = {1990},
	keywords = {Mathematics / Probability \& Statistics / General, Philosophy / General, Philosophy / Logic}
}

@incollection{nozick_newcombs_1969,
	address = {Dordrecht},
	series = {Synthese {Library}},
	title = {Newcomb’s {Problem} and {Two} {Principles} of {Choice}},
	isbn = {978-94-017-1466-2},
	url = {https://doi.org/10.1007/978-94-017-1466-2_7},
	abstract = {Suppose a being in whose power to predict your choices you have enormous confidence. (One might tell a science-fiction story about a being from another planet, with an advanced technology and science, who you know to be friendly, etc.) You know that this being has often correctly predicted your choices in the past (and has never, so far as you know, made an incorrect prediction about your choices), and furthermore you know that this being has often correctly predicted the choices of other people, many of whom are similar to you, in the particular situation to be described below. One might tell a longer story, but all this leads you to believe that almost certainly this being’s prediction about your choice in the situation to be discussed will be correct.},
	language = {en},
	urldate = {2019-02-01},
	booktitle = {Essays in {Honor} of {Carl} {G}. {Hempel}: {A} {Tribute} on the {Occasion} of his {Sixty}-{Fifth} {Birthday}},
	publisher = {Springer Netherlands},
	author = {Nozick, Robert},
	editor = {Rescher, Nicholas},
	year = {1969},
	doi = {10.1007/978-94-017-1466-2_7},
	keywords = {Academic Life, Conditional Probability, Expected Utility, None None, Professional Athlete},
	pages = {114--146}
}

@misc{noauthor_preliminary_nodate,
	title = {Preliminary {Survey} results {\textbar} {PhilPapers} {Surveys}},
	url = {https://philpapers.org/surveys/results.pl?affil=All+respondents&areas0=0&areas_max=1&grain=fine},
	author={Chalmers, David J. and Bourget, David},
	language = {en},
	urldate = {2018-12-20}
}

@phdthesis{lattimore_learning_2017,
	type = {Ph.{D}. {Thesis}},
	title = {Learning how to act:  making good decisions with machine learning},
	url = {https://www.fastmailusercontent.com/mail-attachment/f2132276u33560/%3C4D462F7FBE498F40B1EF178A3570E26C%40ausprd01.prod.outlook.com%3E/finn-lattimore-thesis.pdf?u=9a2e41ab&a=c14836be8a71aac89cdc58faa50dcfcc62b9520c},
	urldate = {2018-01-29},
	school = {Australian National University},
	author = {Lattimore, Finn},
	year = {2017},
	file = {finn-lattimore-thesis.pdf:C\:\\Users\\david\\Zotero\\storage\\9EQBXZCD\\finn-lattimore-thesis.pdf:application/pdf}
}

@article{matus_conditional_1995,
	title = {Conditional {Independences} among {Four} {Random} {Variables} {I}*},
	volume = {4},
	issn = {1469-2163, 0963-5483},
	url = {https://www.cambridge.org/core/journals/combinatorics-probability-and-computing/article/conditional-independences-among-four-random-variables-i/D130040F594FB6EBEF416DA425D3A4A5},
	doi = {10.1017/S0963548300001644},
	abstract = {The conditional independences within a system of four discrete random variables are studied simultaneously. The problem of where independences can occur at the same time, called the problem of probabilistic representability, is attacked by an analysis of cones of polymatroids. New results on the cone of all polymatroids satisfying Ingleton inequalities imply a substantial reduction of the problem and an explicit description of the remaining open cases.†},
	language = {en},
	number = {3},
	urldate = {2019-02-05},
	journal = {Combinatorics, Probability and Computing},
	author = {Matúš, F. and Studený, M.},
	month = sep,
	year = {1995},
	pages = {269--278},
	file = {Full Text PDF:/home/david/Zotero/storage/GN5QDZUY/Matúš and Studený - 1995 - Conditional Independences among Four Random Variab.pdf:application/pdf;Snapshot:/home/david/Zotero/storage/5HBRQ5BP/D130040F594FB6EBEF416DA425D3A4A5.html:text/html}
}

@article{cartwright_what_2009,
	title = {What are randomised controlled trials good for?},
	volume = {147},
	issn = {1573-0883},
	url = {https://doi.org/10.1007/s11098-009-9450-2},
	doi = {10.1007/s11098-009-9450-2},
	abstract = {Randomized controlled trials (RCTs) are widely taken as the gold standard for establishing causal conclusions. Ideally conducted they ensure that the treatment ‘causes’ the outcome—in the experiment. But where else? This is the venerable question of external validity. I point out that the question comes in two importantly different forms: Is the specific causal conclusion warranted by the experiment true in a target situation? What will be the result of implementing the treatment there? This paper explains how the probabilistic theory of causality implies that RCTs can establish causal conclusions and thereby provides an account of what exactly that causal conclusion is. Clarifying the exact form of the conclusion shows just what is necessary for it to hold in a new setting and also how much more is needed to see what the actual outcome would be there were the treatment implemented.},
	language = {en},
	number = {1},
	urldate = {2019-02-04},
	journal = {Philosophical Studies},
	author = {Cartwright, Nancy},
	month = oct,
	year = {2009},
	keywords = {Capacities, Causal inference, Contributions, External validity, Probabilistic theory of causality, Randomized controlled trials (RCTs)},
	pages = {59},
	file = {Springer Full Text PDF:C\:\\Users\\david\\Zotero\\storage\\SZ2QCLS8\\Cartwright - 2009 - What are randomised controlled trials good for.pdf:application/pdf}
}

@incollection{teira_causality_2013,
	address = {Dordrecht},
	series = {History, {Philosophy} and {Theory} of the {Life} {Sciences}},
	title = {Causality, {Impartiality} and {Evidence}-{Based} {Policy}},
	isbn = {978-94-007-2454-9},
	url = {https://doi.org/10.1007/978-94-007-2454-9_11},
	abstract = {The overall aims of this chapter are to compare the use of randomised evaluations in medicine and economics and to assess their ability to provide impartial evidence about causal claims. We will argue that there are no good reasons to regard randomisation as a sine qua non for good evidential practice in either science. However, in medicine, but not in development economics, randomisation can provide impartiality from the point of view of regulatory agencies. The intuition is that if the available evidence leaves room for uncertainty about the effects of an intervention (such as a new drug), a regulator should make sure that such uncertainty cannot be exploited by some party’s private interest. We will argue that randomisation plays an important role in this context. By contrast, in the field evaluations that have recently become popular in development economics, subjects have incentives to act strategically against the research protocol which undermines their use as neutral arbiter between conflicting parties.},
	language = {en},
	urldate = {2019-02-04},
	booktitle = {Mechanism and {Causality} in {Biology} and {Economics}},
	publisher = {Springer Netherlands},
	author = {Teira, David and Reiss, Julian},
	editor = {Chao, Hsiang-Ke and Chen, Szu-Ting and Millstein, Roberta L.},
	year = {2013},
	doi = {10.1007/978-94-007-2454-9_11},
	keywords = {Causal Claim, Expert Judgement, External Validity, Mechanical Objectivity, Regulatory Decision},
	pages = {207--224}
}

@article{spirtes_algorithm_1991,
	title = {An {Algorithm} for {Fast} {Recovery} of {Sparse} {Causal} {Graphs}},
	volume = {9},
	issn = {0894-4393},
	url = {https://doi.org/10.1177/089443939100900106},
	doi = {10.1177/089443939100900106},
	abstract = {Previous asymptotically correct algorithms for recovering causal structure from sample probabilities have been limited even in sparse causal graphs to a few variables. We describe an asymptotically correct algorithm whose complexity for fixed graph connectivity increases polynomially in the number of vertices, and may in practice recover sparse graphs with several hundred variables. From sample data with n = 20,000, an implementation of the algorithm on a DECStation 3100 recovers the edges in a linear version of the ALARM network with 37 vertices and 46 edges. Fewer than 8\% of the undirected edges are incorrectly identified in the output. Without prior ordering information, the program also determines the direction of edges for the ALARM graph with an error rate of 14\%. Processing time is less than 10 seconds. Keywords DAGS, Causal Modelling.},
	language = {en},
	number = {1},
	urldate = {2019-02-05},
	journal = {Social Science Computer Review},
	author = {Spirtes, Peter and Glymour, Clark},
	month = apr,
	year = {1991},
	pages = {62--72},
	file = {SAGE PDF Full Text:/home/david/Zotero/storage/JJA8NDFE/Spirtes and Glymour - 1991 - An Algorithm for Fast Recovery of Sparse Causal Gr.pdf:application/pdf}
}

@article{peters_structural_2013,
	title = {Structural {Intervention} {Distance} ({SID}) for {Evaluating} {Causal} {Graphs}},
	url = {http://arxiv.org/abs/1306.1043},
	abstract = {Causal inference relies on the structure of a graph, often a directed acyclic graph (DAG). Different graphs may result in different causal inference statements and different intervention distributions. To quantify such differences, we propose a (pre-) distance between DAGs, the structural intervention distance (SID). The SID is based on a graphical criterion only and quantifies the closeness between two DAGs in terms of their corresponding causal inference statements. It is therefore well-suited for evaluating graphs that are used for computing interventions. Instead of DAGs it is also possible to compare CPDAGs, completed partially directed acyclic graphs that represent Markov equivalence classes. Since it differs significantly from the popular Structural Hamming Distance (SHD), the SID constitutes a valuable additional measure. We discuss properties of this distance and provide an efficient implementation with software code available on the first author's homepage (an R package is under construction).},
	urldate = {2018-02-20},
	journal = {arXiv:1306.1043 [stat]},
	author = {Peters, Jonas and Bühlmann, Peter},
	month = jun,
	year = {2013},
	note = {arXiv: 1306.1043},
	keywords = {Statistics - Machine Learning},
	file = {arXiv\:1306.1043 PDF:/home/users/u4533535/Zotero/storage/XKLD3IZ9/Peters and Bühlmann - 2013 - Structural Intervention Distance (SID) for Evaluat.pdf:application/pdf;arXiv.org Snapshot:/home/users/u4533535/Zotero/storage/BFJYMINB/1306.html:text/html}
}

@inproceedings{meek_strong_2013,
	title = {Strong {Completeness} and {Faithfulness} in {Bayesian} {Networks}},
	url = {https://arxiv.org/abs/1302.4973},
	booktitle = {Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence},
	language = {en},
	urldate = {2018-05-21},
	author = {Meek, Christopher},
	month = feb,
	year = {2013},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/4JIRGSD9/Meek - 2013 - Strong Completeness and Faithfulness in Bayesian N.pdf:application/pdf}
}

@article{uhler_geometry_2013,
	title = {Geometry of the faithfulness assumption in causal inference},
	volume = {41},
	issn = {0090-5364},
	url = {http://arxiv.org/abs/1207.0547},
	doi = {10.1214/12-AOS1080},
	abstract = {Many algorithms for inferring causality rely heavily on the faithfulness assumption. The main justification for imposing this assumption is that the set of unfaithful distributions has Lebesgue measure zero, since it can be seen as a collection of hypersurfaces in a hypercube. However, due to sampling error the faithfulness condition alone is not sufficient for statistical estimation, and strong-faithfulness has been proposed and assumed to achieve uniform or high-dimensional consistency. In contrast to the plain faithfulness assumption, the set of distributions that is not strong-faithful has nonzero Lebesgue measure and in fact, can be surprisingly large as we show in this paper. We study the strong-faithfulness condition from a geometric and combinatorial point of view and give upper and lower bounds on the Lebesgue measure of strong-faithful distributions for various classes of directed acyclic graphs. Our results imply fundamental limitations for the PC-algorithm and potentially also for other algorithms based on partial correlation testing in the Gaussian case.},
	number = {2},
	urldate = {2018-03-26},
	journal = {The Annals of Statistics},
	author = {Uhler, Caroline and Raskutti, Garvesh and Bühlmann, Peter and Yu, Bin},
	month = apr,
	year = {2013},
	note = {arXiv: 1207.0547},
	keywords = {Mathematics - Statistics Theory},
	pages = {436--463},
	annote = {For linear models with Gaussian noise, strong-faithfulness fails for {\textasciitilde}all models with {\textgreater}10 variables.
 
Comment: Published in at http://dx.doi.org/10.1214/12-AOS1080 the Annals of Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical Statistics (http://www.imstat.org)},
	file = {arXiv\:1207.0547 PDF:/home/users/u4533535/Zotero/storage/JSVPBL65/Uhler et al. - 2013 - Geometry of the faithfulness assumption in causal .pdf:application/pdf;arXiv.org Snapshot:/home/users/u4533535/Zotero/storage/CA726KEA/1207.html:text/html}
}

@article{cooper_bayesian_1992,
	title = {A {Bayesian} method for the induction of probabilistic networks from data},
	volume = {9},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/BF00994110},
	doi = {10.1007/BF00994110},
	abstract = {This paper presents a Bayesian method for constructing probabilistic networks from databases. In particular, we focus on constructing Bayesian belief networks. Potential applications include computer-assisted hypothesis testing, automated scientific discovery, and automated construction of probabilistic expert systems. We extend the basic method to handle missing data and hidden (latent) variables. We show how to perform probabilistic inference by averaging over the inferences of multiple belief networks. Results are presented of a preliminary evaluation of an algorithm for constructing a belief network from a database of cases. Finally, we relate the methods in this paper to previous work, and we discuss open problems.},
	language = {en},
	number = {4},
	urldate = {2019-02-05},
	journal = {Machine Learning},
	author = {Cooper, Gregory F. and Herskovits, Edward},
	month = oct,
	year = {1992},
	keywords = {Bayesian belief networks, induction, machine learning, probabilistic networks},
	pages = {309--347},
	file = {Springer Full Text PDF:/home/david/Zotero/storage/ARGAXIFR/Cooper and Herskovits - 1992 - A Bayesian method for the induction of probabilist.pdf:application/pdf}
}

@article{malone2014scoring,
	title = {Empirical evaluation of scoring functions for {Bayesian} network model selection},
	volume = {13},
	issn = {1471-2105},
	url = {https://doi.org/10.1186/1471-2105-13-S15-S14},
	doi = {10.1186/1471-2105-13-S15-S14},
	abstract = {In this work, we empirically evaluate the capability of various scoring functions of Bayesian networks for recovering true underlying structures. Similar investigations have been carried out before, but they typically relied on approximate learning algorithms to learn the network structures. The suboptimal structures found by the approximation methods have unknown quality and may affect the reliability of their conclusions. Our study uses an optimal algorithm to learn Bayesian network structures from datasets generated from a set of gold standard Bayesian networks. Because all optimal algorithms always learn equivalent networks, this ensures that only the choice of scoring function affects the learned networks. Another shortcoming of the previous studies stems from their use of random synthetic networks as test cases. There is no guarantee that these networks reflect real-world data. We use real-world data to generate our gold-standard structures, so our experimental design more closely approximates real-world situations. A major finding of our study suggests that, in contrast to results reported by several prior works, the Minimum Description Length (MDL) (or equivalently, Bayesian information criterion (BIC)) consistently outperforms other scoring functions such as Akaike's information criterion (AIC), Bayesian Dirichlet equivalence score (BDeu), and factorized normalized maximum likelihood (fNML) in recovering the underlying Bayesian network structures. We believe this finding is a result of using both datasets generated from real-world applications rather than from random processes used in previous studies and learning algorithms to select high-scoring structures rather than selecting random models. Other findings of our study support existing work, e.g., large sample sizes result in learning structures closer to the true underlying structure; the BDeu score is sensitive to the parameter settings; and the fNML performs pretty well on small datasets. We also tested a greedy hill climbing algorithm and observed similar results as the optimal algorithm.},
	number = {15},
	urldate = {2019-02-08},
	journal = {BMC Bioinformatics},
	author = {Liu, Zhifa and Malone, Brandon and Yuan, Changhe},
	month = sep,
	year = {2012},
	pages = {S14}
}

@article{heckerman_learning_1995,
	title = {Learning {Bayesian} networks: {The} combination of knowledge and statistical data},
	volume = {20},
	issn = {1573-0565},
	shorttitle = {Learning {Bayesian} networks},
	url = {https://doi.org/10.1007/BF00994016},
	doi = {10.1007/BF00994016},
	abstract = {We describe a Bayesian approach for learning Bayesian networks from a combination of prior knowledge and statistical data. First and foremost, we develop a methodology for assessing informative priors needed for learning. Our approach is derived from a set of assumptions made previously as well as the assumption oflikelihood equivalence, which says that data should not help to discriminate network structures that represent the same assertions of conditional independence. We show that likelihood equivalence when combined with previously made assumptions implies that the user's priors for network parameters can be encoded in a single Bayesian network for the next case to be seen—aprior network—and a single measure of confidence for that network. Second, using these priors, we show how to compute the relative posterior probabilities of network structures given data. Third, we describe search methods for identifying network structures with high posterior probabilities. We describe polynomial algorithms for finding the highest-scoring network structures in the special case where every node has at mostk=1 parent. For the general case (k{\textgreater}1), which is NP-hard, we review heuristic search algorithms including local search, iterative local search, and simulated annealing. Finally, we describe a methodology for evaluating Bayesian-network learning algorithms, and apply this approach to a comparison of various approaches.},
	language = {en},
	number = {3},
	urldate = {2019-02-05},
	journal = {Machine Learning},
	author = {Heckerman, David and Geiger, Dan and Chickering, David M.},
	month = sep,
	year = {1995},
	keywords = {Bayesian networks, Dirichlet, heuristic search, learning, likelihood equivalence, maximum branching},
	pages = {197--243},
	file = {Springer Full Text PDF:/home/david/Zotero/storage/39N52JBT/Heckerman et al. - 1995 - Learning Bayesian networks The combination of kno.pdf:application/pdf}
}

@inproceedings{claassen_learning_2013,
	title = {Learning {Sparse} {Causal} {Models} is not {NP}-hard},
	url = {https://arxiv.org/abs/1309.6824v1},
	abstract = {This paper shows that causal model discovery is not an NP-hard problem, in
the sense that for sparse graphs bounded by node degree k the sound and
complete causal model can be obtained in worst case order N{\textasciicircum}\{2(k+2)\}
independence tests, even when latent variables and selection bias may be
present. We present a modification of the well-known FCI algorithm that
implements the method for an independence oracle, and suggest improvements for
sample/real-world data versions. It does not contradict any known hardness
results, and does not solve an NP-hard problem: it just proves that sparse
causal discovery is perhaps more complicated, but not as hard as learning
minimal Bayesian networks.},
	language = {en},
	urldate = {2019-02-07},
	booktitle = {UAI'13 Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
	author = {Claassen, Tom and Mooij, Joris and Heskes, Tom},
	month = sep,
	year = {2013},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/TW5WSFES/Claassen et al. - 2013 - Learning Sparse Causal Models is not NP-hard.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/M5TLE7RV/1309.html:text/html}
}

@article{colombo_learning_2012,
	title = {Learning high-dimensional directed acyclic graphs with latent and selection variables},
	volume = {40},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/euclid.aos/1333567191},
	doi = {10.1214/11-AOS940},
	abstract = {We consider the problem of learning causal information between random variables in directed acyclic graphs (DAGs) when allowing arbitrarily many latent and selection variables. The FCI (Fast Causal Inference) algorithm has been explicitly designed to infer conditional independence and causal information in such settings. However, FCI is computationally infeasible for large graphs. We therefore propose the new RFCI algorithm, which is much faster than FCI. In some situations the output of RFCI is slightly less informative, in particular with respect to conditional independence information. However, we prove that any causal information in the output of RFCI is correct in the asymptotic limit. We also define a class of graphs on which the outputs of FCI and RFCI are identical. We prove consistency of FCI and RFCI in sparse high-dimensional settings, and demonstrate in simulations that the estimation performances of the algorithms are very similar. All software is implemented in the R-package pcalg.},
	language = {EN},
	number = {1},
	urldate = {2019-02-07},
	journal = {The Annals of Statistics},
	author = {Colombo, Diego and Maathuis, Marloes H. and Kalisch, Markus and Richardson, Thomas S.},
	month = feb,
	year = {2012},
	mrnumber = {MR3014308},
	zmnumber = {1246.62131},
	keywords = {Causal structure learning, consistency, FCI algorithm, high-dimensionality, maximal ancestral graphs (MAGs), partial ancestral graphs (PAGs), RFCI algorithm, sparsity},
	pages = {294--321},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/ED3K7B2J/Colombo et al. - 2012 - Learning high-dimensional directed acyclic graphs .pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/DXHGGJBS/1333567191.html:text/html}
}



@article{kolmogorov_three_1968,
	title = {Three approaches to the quantitative definition of information},
	volume = {2},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00207166808803030},
	doi = {10.1080/00207166808803030},
	number = {1-4},
	urldate = {2019-02-06},
	journal = {International Journal of Computer Mathematics},
	author = {Kolmogorov, A. N.},
	month = jan,
	year = {1968},
	pages = {157--168}
}


@inproceedings{kano_causal_2003,
	title = {Causal inference using nonnormality},
	author = {Kano, Yutaka and Shimizu, Shohei},
	booktitle = {Proceedings of the international symposium on science of modeling},
	year = {2003}
}

@article{hoyer_estimation_2008,
	series = {Special {Section} on {Probabilistic} {Rough} {Sets} and {Special} {Section} on {PGM}’06},
	title = {Estimation of causal effects using linear non-{Gaussian} causal models with hidden variables},
	volume = {49},
	issn = {0888-613X},
	url = {http://www.sciencedirect.com/science/article/pii/S0888613X08000212},
	doi = {10.1016/j.ijar.2008.02.006},
	abstract = {The task of estimating causal effects from non-experimental data is notoriously difficult and unreliable. Nevertheless, precisely such estimates are commonly required in many fields including economics and social science, where controlled experiments are often impossible. Linear causal models (structural equation models), combined with an implicit normality (Gaussianity) assumption on the data, provide a widely used framework for this task. We have recently described how non-Gaussianity in the data can be exploited for estimating causal effects. In this paper we show that, with non-Gaussian data, causal inference is possible even in the presence of hidden variables (unobserved confounders), even when the existence of such variables is unknown a priori. Thus, we provide a comprehensive and complete framework for the estimation of causal effects between the observed variables in the linear, non-Gaussian domain. Numerical simulations demonstrate the practical implementation of the proposed method, with full Matlab code available for all simulations.},
	number = {2},
	urldate = {2019-02-07},
	journal = {International Journal of Approximate Reasoning},
	author = {Hoyer, Patrik O. and Shimizu, Shohei and Kerminen, Antti J. and Palviainen, Markus},
	month = oct,
	year = {2008},
	keywords = {Structural equation models, Latent variables, Causal discovery, Independent component analysis, Non-Gaussianity},
	pages = {362--378}
}

@article{mooij_j.m._distinguishing_2016,
	title = {Distinguishing {Cause} from {Effect} {Using} {Observational} {Data}: {Methods} and {Benchmarks}},
	volume = {17},
	issn = {1532-4435},
	shorttitle = {Distinguishing {Cause} from {Effect} {Using} {Observational} {Data}},
	url = {http://dare.uva.nl/personal/pure/en/publications/distinguishing-cause-from-effect-using-observational-data-methods-and-benchmarks(f4e35a2b-cd22-41a4-93e5-7f0b1cf8090a).html},
	abstract = {The discovery of causal relationships from purely observational data is a fundamental problem in science. The most elementary form of such a causal discovery problem is to decide whether X causes Y or, alternatively, Y causes X, given joint observations of two variables X,Y. An example is to decide whether altitude causes temperature, or vice versa, given only joint measurements of both variables. Even under the simplifying assumptions of no confounding, no feedback loops, and no selection bias, such bivariate causal discovery problems are challenging. Nevertheless, several approaches for addressing those problems have been proposed in recent years. We review two families of such methods: methods based on Additive Noise Models (ANMs) and Information Geometric Causal Inference (IGCI). We present the benchmark CauseEffectPairs that consists of data for 100 different cause-effect pairs selected from 37 data sets from various domains (e.g., meteorology, biology, medicine, engineering, economy, etc.) and motivate our decisions regarding the “ground truth” causal directions of all pairs. We evaluate the performance of several bivariate causal discovery methods on these real-world benchmark data and in addition on artificially simulated data. Our empirical results on real-world data indicate that certain methods are indeed able to distinguish cause from effect using only purely observational data, although more benchmark data would be needed to obtain statistically significant conclusions. One of the best performing methods overall is the method based on Additive Noise Models that has originally been proposed by Hoyer et al. (2009), which obtains an accuracy of 63 ± 10 \% and an AUC of 0.74 ± 0.05 on the real-world benchmark. As the main theoretical contribution of this work we prove the consistency of that method.},
	language = {en},
	urldate = {2019-02-07},
	journal = {Journal of Machine Learning Research},
	author = {{Mooij, J.M.} and {Peters, J.} and {Janzing, D.} and {Zscheischler, J.} and {Schölkopf, B.} and {Amsterdam Machine Learning lab (IVI, FNWI)}},
	year = {2016},
	keywords = {A - open article in open journal}
}

@misc{press_elements_nodate,
	title = {Elements of {Causal} {Inference}},
	url = {https://mitpress.mit.edu/books/elements-causal-inference},
	abstract = {A concise and self-contained introduction to causal inference, increasingly important in data science and machine learning.
                The mathematization of causality is a relatively recent development, and has become increasingly important in data science and machine learning. This book offers a self-contained and concise introduction to causal models and how to learn them from data.
                    After explaining the need for causal models and discussing some of the principles underlying causal inference, the book teaches readers how to use causal models: how to compute intervention distributions, how to infer causal models from observational and interventional data, and how causal ideas could be exploited for classical machine learning problems. All of these topics are discussed first in terms of two variables and then in the more general multivariate case. The bivariate case turns out to be a particularly hard problem for causal learning because there are no conditional independences as used by classical methods for solving multivariate cases. The authors consider analyzing statistical asymmetries between cause and effect to be highly instructive, and they report on their decade of intensive research into this problem. The book is accessible to readers with a background in machine learning or statistics, and can be used in graduate courses or as a reference for researchers. The text includes code snippets that can be copied and pasted, exercises, and an appendix with a summary of the most important technical concepts.},
	language = {en},
	urldate = {2019-02-07},
	year = {2019},
	journal = {The MIT Press},
	author = {Press, The MIT}
}

@inproceedings{budhathoki_causal_2016,
	title = {Causal {Inference} by {Compression}},
	doi = {10.1109/ICDM.2016.0015},
	abstract = {Causal inference is one of the fundamental problems in science. In recent years, several methods have been proposed for discovering causal structure from observational data. These methods, however, focus specifically on numeric data, and are not applicable on nominal or binary data. In this work, we focus on causal inference for binary data. Simply put, we propose causal inference by compression. To this end we propose an inference framework based on solid information theoretic foundations, i.e. Kolmogorov complexity. However, Kolmogorov complexity is not computable, and hence we propose a practical and computable instantiation based on the Minimum Description Length (MDL) principle. To apply the framework in practice, we propose ORIGO, an efficient method for inferring the causal direction from binary data. ORIGO employs the lossless PACK compressor, works directly on the data and does not require assumptions about neither distributions nor the type of causal relations. Extensive evaluation on synthetic, benchmark, and real-world data shows that ORIGO discovers meaningful causal relations, and outperforms state-of-the-art methods by a wide margin.},
	booktitle = {2016 {IEEE} 16th {International} {Conference} on {Data} {Mining} ({ICDM})},
	author = {Budhathoki, K. and Vreeken, J.},
	month = dec,
	year = {2016},
	keywords = {causal inference, Benchmark testing, binary data compression, causal structure, Complexity theory, data compression, Decision trees, Drugs, Inference algorithms, inference mechanisms, Informatics, information theoretic foundations, information theory, Information theory, lossless PACK compressor, mdl, MDL principle, minimum description length principle, observational data, ORIGO},
	pages = {41--50}
}

@article{chickering_learning_2002,
	title = {Learning {Equivalence} {Classes} of {Bayesian}-{Network} {Structures}},
	volume = {2},
	issn = {ISSN 1533-7928},
	url = {http://www.jmlr.org/papers/v2/chickering02a.html},
	number = {Feb},
	urldate = {2018-10-14},
	journal = {Journal of Machine Learning Research},
	author = {Chickering, David Maxwell},
	year = {2002},
	pages = {445--498},
	file = {Full Text PDF:C\:\\Users\\david\\Zotero\\storage\\2GCGWWCH\\Chickering - 2002 - Learning Equivalence Classes of Bayesian-Network S.pdf:application/pdf;Snapshot:C\:\\Users\\david\\Zotero\\storage\\R5C8YEYE\\chickering02a.html:text/html}
}

@article{splawa-neyman_application_1990,
	title = {On the {Application} of {Probability} {Theory} to {Agricultural} {Experiments}. {Essay} on {Principles}. {Section} 9.},
	volume = {5},
	issn = {0883-4237},
	url = {https://www.jstor.org/stable/2245382},
	abstract = {[In the portion of the paper translated here, Neyman introduces a model for the analysis of field experiments conducted for the purpose of comparing a number of crop varieties, which makes use of a double-indexed array of unknown potential yields, one index corresponding to varieties and the other to plots. The yield corresponding to only one variety will be observed on any given plot, but through an urn model embodying sampling without replacement from this doubly indexed array, Neyman obtains a formula for the variance of the difference between the averages of the observed yields of two varieties. This variance involves the variance over all plots of the potential yields and the correlation coefficient r between the potential yields of the two varieties on the same plot. Since it is impossible to estimate r directly, Neyman advises taking r = 1, observing that in practice this may lead to using too large an estimated standard deviation, when comparing two variety means.]},
	number = {4},
	urldate = {2019-02-07},
	journal = {Statistical Science},
	author = {Splawa-Neyman, Jerzy and Dabrowska, D. M. and Speed, T. P.},
	year = {1990},
	pages = {465--472}
}

@article{balke_bounds_1997,
	title = {Bounds on {Treatment} {Effects} from {Studies} with {Imperfect} {Compliance}},
	volume = {92},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.1997.10474074},
	doi = {10.1080/01621459.1997.10474074},
	abstract = {This article establishes nonparametric formulas that can be used to bound the average treatment effect in experimental studies in which treatment assignment is random but subject compliance is imperfect. The bounds provided are the tightest possible, given the distribution of assignments, treatments, and responses. The formulas show that even with high rates of noncompliance, experimental data can yield useful and sometimes accurate information on the average effect of a treatment on the population.},
	number = {439},
	urldate = {2019-02-07},
	journal = {Journal of the American Statistical Association},
	author = {Balke, Alexander and Pearl, Judea},
	month = sep,
	year = {1997},
	keywords = {Causal models, Latent variables, Linear programming, Noncompliance},
	pages = {1171--1176},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/IA6KFTGS/Balke and Pearl - 1997 - Bounds on Treatment Effects from Studies with Impe.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/T6L58QSW/01621459.1997.html:text/html}
}


@article{angrist_instrumental_2001,
	title = {Instrumental {Variables} and the {Search} for {Identification}: {From} {Supply} and {Demand} to {Natural} {Experiments}},
	volume = {15},
	issn = {0895-3309},
	shorttitle = {Instrumental {Variables} and the {Search} for {Identification}},
	url = {https://www.aeaweb.org/articles?id=10.1257/jep.15.4.69},
	doi = {10.1257/jep.15.4.69},
	abstract = {Instrumental variables was first used in the 1920s to estimate supply and demand elasticities and later to correct for measurement error in single equation models. Recently, instrumental variables have been widely used to reduce bias from omitted variables in estimates of causal relationships. Intuitively, instrumental variables methods use only a portion of the variability in key variables to estimate the relationships of interest; if the instruments are valid, that portion is unrelated to the omitted variables. We discuss the mechanics of instrumental variables and the qualities that make for a good instrument, devoting particular attention to instruments derived from "natural experiments."},
	language = {en},
	number = {4},
	urldate = {2019-02-07},
	journal = {Journal of Economic Perspectives},
	author = {Angrist, Joshua D. and Krueger, Alan B.},
	month = dec,
	year = {2001},
	keywords = {Multiple or Simultaneous Equation Models: General},
	pages = {69--85},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/H7DWZJ6W/Angrist and Krueger - 2001 - Instrumental Variables and the Search for Identifi.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/FISML2CL/articles.html:text/html}
}

@article{imai_covariate_2014,
	title = {Covariate balancing propensity score},
	volume = {76},
	copyright = {© 2013 Royal Statistical Society},
	issn = {1467-9868},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12027},
	doi = {10.1111/rssb.12027},
	abstract = {The propensity score plays a central role in a variety of causal inference settings. In particular, matching and weighting methods based on the estimated propensity score have become increasingly common in the analysis of observational data. Despite their popularity and theoretical appeal, the main practical difficulty of these methods is that the propensity score must be estimated. Researchers have found that slight misspecification of the propensity score model can result in substantial bias of estimated treatment effects. We introduce covariate balancing propensity score (CBPS) methodology, which models treatment assignment while optimizing the covariate balance. The CBPS exploits the dual characteristics of the propensity score as a covariate balancing score and the conditional probability of treatment assignment. The estimation of the CBPS is done within the generalized method-of-moments or empirical likelihood framework. We find that the CBPS dramatically improves the poor empirical performance of propensity score matching and weighting methods reported in the literature. We also show that the CBPS can be extended to other important settings, including the estimation of the generalized propensity score for non-binary treatments and the generalization of experimental estimates to a target population. Open source software is available for implementing the methods proposed.},
	language = {en},
	number = {1},
	urldate = {2019-02-07},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Imai, Kosuke and Ratkovic, Marc},
	year = {2014},
	keywords = {Causal inference, Instrumental variables, Inverse propensity score weighting, Marginal structural models, Observational studies, Propensity score matching, Randomized experiments},
	pages = {243--263},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/96TZS5DB/Imai and Ratkovic - 2014 - Covariate balancing propensity score.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/KPP95H24/rssb.html:text/html}
}

@article{dorie_automated_2017,
	title = {Automated versus do-it-yourself methods for causal inference: {Lessons} learned from a data analysis competition},
	shorttitle = {Automated versus do-it-yourself methods for causal inference},
	url = {http://arxiv.org/abs/1707.02641},
	abstract = {Statisticians have made great strides towards assumption-free estimation of causal estimands in the past few decades. However this explosion in research has resulted in a breadth of inferential strategies that both create opportunities for more reliable inference as well as complicate the choices that an applied researcher has to make and defend. Relatedly, researchers advocating for new methods typically compare their method to (at best) 2 or 3 other causal inference strategies and test using simulations that may or may not be designed to equally tease out flaws in all the competing methods. The causal inference data analysis challenge, "Is Your SATT Where It's At?", launched as part of the 2016 Atlantic Causal Inference Conference, sought to make progress with respect to both of these issues. The researchers creating the data testing grounds were distinct from the researchers submitting methods whose efficacy would be evaluated. Results from 30 competitors across the two versions of the competition (black box algorithms and do-it-yourself analyses) are presented along with post-hoc analyses that reveal information about the characteristics of causal inference strategies and settings that affect performance. The most consistent conclusion was that methods that flexibly model the response surface perform better overall than methods that fail to do so.},
	urldate = {2018-01-26},
	journal = {arXiv:1707.02641 [stat]},
	author = {Dorie, Vincent and Hill, Jennifer and Shalit, Uri and Scott, Marc and Cervone, Dan},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.02641},
	keywords = {Statistics - Machine Learning, Statistics - Methodology},
	file = {arXiv\:1707.02641 PDF:/home/users/u4533535/Zotero/storage/RERVWSYT/Dorie et al. - 2017 - Automated versus do-it-yourself methods for causal.pdf:application/pdf;arXiv.org Snapshot:/home/users/u4533535/Zotero/storage/FU8VGHXK/1707.html:text/html}
}

@article{fraker_adequacy_1987,
	title = {The {Adequacy} of {Comparison} {Group} {Designs} for {Evaluations} of {Employment}-{Related} {Programs}},
	volume = {22},
	issn = {0022-166X},
	url = {https://www.jstor.org/stable/145902},
	doi = {10.2307/145902},
	abstract = {[This study investigates empirically the strengths and limitations of using experimental versus nonexperimental designs for evaluating employment and training programs. The assessment involves comparing results from an experimental-design study-the National Supported Work Demonstration-with the estimated impacts of Supported Work based on analyses using comparison groups constructed from the Current Population Surveys. The results indicate that nonexperimental designs cannot be relied on to estimate the effectiveness of employment programs. Impact estimates tend to be sensitive both to the comparison group construction methodology and to the analytic model used. There is currently no way a priori to ensure that the results of comparison group studies will be valid indicators of the program impacts.]},
	number = {2},
	urldate = {2019-02-07},
	journal = {The Journal of Human Resources},
	author = {Fraker, Thomas and Maynard, Rebecca},
	year = {1987},
	pages = {194--227}
}

@article{lalonde_evaluating_1986,
	title = {Evaluating the {Econometric} {Evaluations} of {Training} {Programs} with {Experimental} {Data}},
	volume = {76},
	issn = {0002-8282},
	url = {https://www.jstor.org/stable/1806062},
	abstract = {This paper compares the effect on trainee earnings of an employment program that was run as a field experiment where participants were randomly assigned to treatment and control groups with the estimates that would have been produced by an econometrician. This comparison shows that many of the econometric procedures do not replicate the experimentally determined results, and it suggests that researchers should be aware of the potential for specification errors in other nonexperimental evaluations.},
	number = {4},
	urldate = {2019-02-07},
	journal = {The American Economic Review},
	author = {LaLonde, Robert J.},
	year = {1986},
	pages = {604--620}
}

@article{sjolander_propensity_2009,
	title = {Propensity scores and {M}-structures},
	volume = {28},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.3532},
	doi = {10.1002/sim.3532},
	abstract = {In a recent issue of Statistics in Medicine, Ian Shrier [Statist. Med. 2008; 27(14):2740–2741] posed a question regarding the use of propensity scores [Biometrika 1983; 70(1):41–55]. He considered an ‘M-structure’ illustrated by the directed acyclic graph (DAG) in Figure 1. In Figure 1, z is a binary exposure, r is a response of interest, x is a measured covariate, and u1 and u2 are two unmeasured covariates. Shrier stated that for the M-structure, ‘... it remains unclear if the propensity method described by Rubin would introduce selection bias or not’. In the same issue, Donald Rubin [Statist. Med. 2002; 27(14):2741–2742] replied by clarifying several key points in the use of propensity scores. He did not, however, discuss the original question posed by Shrier. Given the popularity of both propensity score methods and graphical models, I think any confusion regarding the appropriateness of these methods deserves serious attention and I would therefore like to answer Shrier's question here. The short answer is that for the M-structure, propensity score methods do indeed induce a bias. Below, I will clarify this statement. I will first briefly review the basic idea of propensity scores and then explain why the idea does not apply to the M-structure. I will use a notation which is consistent with Rosenbaum and Rubin [Biometrika 1983; 70(1):41–55]. Copyright © 2009 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {9},
	urldate = {2018-12-19},
	journal = {Statistics in Medicine},
	author = {Sjölander, Arvid},
	year = {2009},
	keywords = {DAG, M-structure, propensity score},
	pages = {1416--1420},
	file = {Snapshot:C\:\\Users\\david\\Zotero\\storage\\LCWWNTBS\\sim.html:text/html}
}

@incollection{hoyer_nonlinear_2009,
	title = {Nonlinear causal discovery with additive noise models},
	url = {http://papers.nips.cc/paper/3548-nonlinear-causal-discovery-with-additive-noise-models.pdf},
	urldate = {2019-02-07},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 21},
	publisher = {Curran Associates, Inc.},
	author = {Hoyer, Patrik O. and Janzing, Dominik and Mooij, Joris M and Peters, Jonas and Schölkopf, Bernhard},
	editor = {Koller, D. and Schuurmans, D. and Bengio, Y. and Bottou, L.},
	year = {2009},
	pages = {689--696},
	file = {NIPS Full Text PDF:C\:\\Users\\david\\Zotero\\storage\\6HDRLF3U\\Hoyer et al. - 2009 - Nonlinear causal discovery with additive noise mod.pdf:application/pdf;NIPS Snapshot:C\:\\Users\\david\\Zotero\\storage\\4PLMCIUN\\3548-nonlinear-causal-discovery-with-additive-noise-models.html:text/html}
}

@misc{noauthor_resolving_2009,
	title = {Resolving disputes between {J}. {Pearl} and {D}. {Rubin} on causal inference},
	url = {https://andrewgelman.com/2009/07/05/disputes_about/},
	abstract = {This is a pretty long one. It’s an attempt to explore some of the differences between Judea Pearl’s and Don Rubin’s approaches to causal inference, and is motivated by recent article by Pearl. Pearl sent me a link to this piece of his, writing: I [Pearl] would like to encourage a blog-discussion on the main …},
	language = {en-US},
	urldate = {2018-12-20},
	author = {Gelman, Andrew},
	journal = {Statistical Modeling, Causal Inference, and Social Science},
	month = jul,
	year = {2009},
	file = {Snapshot:C\:\\Users\\david\\Zotero\\storage\\WUHG43MZ\\disputes_about.html:text/html}
}

@inproceedings{shpitser_identification_2006,
	title = {Identification of {Joint} {Interventional} {Distributions} in {Recursive} {Semi}-{Markovian} {Causal} {Models}},
	url = {https://escholarship.org/uc/item/9598x714},
	abstract = {This paper is concerned with estimating the effects of actions from causal assumptions, represented concisely as a directed graph, and statistical knowledge, given as a probability distribution. We provide a necessary and sufficient graphical condition for the cases when the causal effect of an arbitrary set of variables on another arbitrary set can be determined uniquely from the available information, as well as an algorithm which computes the effect whenever this condition holds. Furthermore, we use our results to prove completeness of do-calculus [Pearl, 1995], and a version of an identification algorithm in [Tian, 2002] for the same identification problem.},
	language = {en},
	booktitle = {Proceedings of the National Conference on Artificial Intelligence},
	urldate = {2019-02-07},
	author = {Shpitser, Ilya and Pearl, Judea},
	month = jul,
	year = {2006},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/UA836NDK/Shpitser and Pearl - 2006 - Identification of Joint Interventional Distributio.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/Y3TVMDTM/9598x714.pdf:application/pdf}
}

@inproceedings{shpitser_effects_2009,
	address = {Arlington, Virginia, United States},
	series = {{UAI} '09},
	title = {Effects of {Treatment} on the {Treated}: {Identification} and {Generalization}},
	isbn = {978-0-9749039-5-8},
	shorttitle = {Effects of {Treatment} on the {Treated}},
	url = {http://dl.acm.org/citation.cfm?id=1795114.1795174},
	abstract = {Many applications of causal analysis call for assessing, retrospectively, the effect of with-holding an action that has in fact been implemented. This counterfactual quantity, sometimes called "effect of treatment on the treated," (ETT) have been used to to evaluate educational programs, critic public policies, and justify individual decision making. In this paper we explore the conditions under which ETT can be estimated from (i.e., identified in) experimental and/or observational studies. We show that, when the action invokes a singleton variable, the conditions for ETT identification have simple characterizations in terms of causal diagrams. We further give a graphical characterization of the conditions under which the effects of multiple treatments on the treated can be identified, as well as ways in which the ETT estimand can be constructed from both interventional and observational distributions.},
	urldate = {2019-02-06},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {AUAI Press},
	author = {Shpitser, Ilya and Pearl, Judea},
	year = {2009},
	note = {event-place: Montreal, Quebec, Canada},
	pages = {514--521}
}

@article{rubin_authors_2008,
	title = {Author's {Reply}},
	volume = {27},
	copyright = {Copyright © 2008 John Wiley \& Sons, Ltd.},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.3231},
	doi = {10.1002/sim.3231},
	language = {en},
	number = {14},
	urldate = {2018-12-19},
	journal = {Statistics in Medicine},
	author = {Rubin, Donald B.},
	year = {2008},
	pages = {2741--2742},
	file = {Full Text PDF:C\:\\Users\\david\\Zotero\\storage\\8C6BTIL9\\Rubin - 2008 - Author's Reply.pdf:application/pdf;Snapshot:C\:\\Users\\david\\Zotero\\storage\\77QLCQXK\\sim.html:text/html}
}

@article{pearl_does_2018,
	title = {Does {Obesity} {Shorten} {Life}? {Or} is it the {Soda}? {On} {Non}-manipulable {Causes}},
	volume = {6},
	shorttitle = {Does {Obesity} {Shorten} {Life}?},
	url = {https://www.degruyter.com/view/j/jci.2018.6.issue-2/jci-2018-2001/jci-2018-2001.xml},
	doi = {10.1515/jci-2018-2001},
	abstract = {Non-manipulable factors, such as gender or race have posed conceptual and practical challenges to causal analysts. On the one hand these factors do have consequences, and on the other hand, they do not fit into the experimentalist conception of causation. This paper addresses this challenge in the context of public debates over the health cost of obesity, and offers a new perspective, based on the theory of Structural Causal Models (SCM).},
	number = {2},
	urldate = {2019-02-04},
	journal = {Journal of Causal Inference},
	author = {Pearl, Judea},
	year = {2018},
	keywords = {causal effect, consistency, counterfactuals, interventions, Manipulability}
}

@article{wright1921correlation,
  title={Correlation and causation},
  journal={Journal of agricultural research},
  year={1921},
  author={Wright, Sewall}
}

@book{bishop_pattern_2006,
	address = {New York},
	series = {Information {Science} and {Statistics}},
	title = {Pattern {Recognition} and {Machine} {Learning}},
	isbn = {978-0-387-31073-2},
	url = {https://www.springer.com/gp/book/9780387310732},
	abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. Christopher M. Bishop is Deputy Director of Microsoft Research Cambridge, and holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, a Fellow of the Royal Academy of Engineering, and a Fellow of the Royal Society of Edinburgh. His previous textbook "Neural Networks for Pattern Recognition" has been widely adopted. Coming soon: *For students, worked solutions to a subset of exercises available on a public web site (for exercises marked "www" in the text) *For instructors, worked solutions to remaining exercises from the Springer web site *Lecture slides to accompany each chapter *Data sets available for download},
	language = {en},
	urldate = {2019-10-08},
	publisher = {Springer-Verlag},
	author = {Bishop, Christopher},
	year = {2006},
	file = {Snapshot:/home/users/u4533535/Zotero/storage/5YXBHEIR/9780387310732.html:text/html}
}

@book{savage_foundations_1972,
	address = {New York},
	edition = {Revised edition},
	title = {Foundations of {Statistics}},
	isbn = {978-0-486-62349-8},
	abstract = {Classic analysis of the foundations of statistics and development of personal probability, one of the greatest controversies in modern statistical thought. Revised edition. Calculus, probability, statistics, and Boolean algebra are recommended.},
	language = {English},
	publisher = {Dover Publications},
	author = {Savage, Leonard J.},
	month = jun,
	year = {1972}
}

@phdthesis{shpitser_complete_2008,
	address = {Los Angeles, CA, USA},
	type = {{PhD} {Thesis}},
	title = {Complete {Identification} {Methods} for {Causal} {Inference}},
	abstract = {Human beings organize their intuitive understanding of the world in terms of causes and effects. Primitive humanity posited gods and spirits as invisible causes of phenomena they did not comprehend. As our attempts to understand the world began to be formalized and codified as empirical science, the emphasis on discerning cause-effect relationships remained. Though we, the modern humanity, are armed with powerful computers, sophisticated technology, and highly developed mathematics and statistics, our fundamental questions remain the same as those of our cave dwelling ancestors – we seek to understand the causes of windfalls and misfortunes that befall us, what effects our actions have, and what would happen if the past were different from what it is. This thesis will address these ancient questions with the rigor and generality of modern mathematics. Using the framework of graphical causal models which formalizes a variety of causal queries, such as causal effects, counterfactuals and path-specific effects as certain types of probability distributions, I will develop algorithms which will evaluate these probability distributions from available information; prove that whenever these algorithms fail to evaluate a query, no other method could succeed; provide characterizations based on directed graphs for cases where these algorithms do succeed; and finally show how a class of constraints placed on the causal model by its directed graph are due to conditional independence in these probability distributions, and how these conditional independencies can be exploited for testing causal theories.},
	school = {University of California at Los Angeles},
	author = {Shpitser, Ilya},
	year = {2008},
	annote = {AAI3351728}
}
@article{dawid_influence_2002,
	title = {Influence {Diagrams} for {Causal} {Modelling} and {Inference}},
	volume = {70},
	issn = {1751-5823},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1751-5823.2002.tb00354.x},
	doi = {10.1111/j.1751-5823.2002.tb00354.x},
	abstract = {We consider a variety of ways in which probabilistic and causal models can be represented in graphical form. By adding nodes to our graphs to represent parameters, decision, etc., we obtain a generalisation of influence diagrams that supports meaningful causal modelling and inference, and only requires concepts and methods that are already standard in the purely probabilistic case. We relate our representations to others, particularly functional models, and present arguments and examples in favour of their superiority.},
	language = {en},
	number = {2},
	urldate = {2019-02-07},
	journal = {International Statistical Review},
	author = {Dawid, A. P.},
	year = {2002},
	keywords = {Causal inference, Augmented DAG, Confounder, Counterfactual, Directed acyclic graph, Functional model, Graphical model, Intervention},
	pages = {161--189},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/8TXLJKZ3/Dawid - 2002 - Influence Diagrams for Causal Modelling and Infere.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/5HXYMQZ8/j.1751-5823.2002.tb00354.html:text/html}
}

@article{maathuis_estimating_2009,
	title = {Estimating high-dimensional intervention effects from observational data},
	volume = {37},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/euclid.aos/1250515382},
	doi = {10.1214/09-AOS685},
	abstract = {We assume that we have observational data generated from an unknown underlying directed acyclic graph (DAG) model. A DAG is typically not identifiable from observational data, but it is possible to consistently estimate the equivalence class of a DAG. Moreover, for any given DAG, causal effects can be estimated using intervention calculus. In this paper, we combine these two parts. For each DAG in the estimated equivalence class, we use intervention calculus to estimate the causal effects of the covariates on the response. This yields a collection of estimated causal effects for each covariate. We show that the distinct values in this set can be consistently estimated by an algorithm that uses only local information of the graph. This local approach is computationally fast and feasible in high-dimensional problems. We propose to use summary measures of the set of possible causal effects to determine variable importance. In particular, we use the minimum absolute value of this set, since that is a lower bound on the size of the causal effect. We demonstrate the merits of our methods in a simulation study and on a data set about riboflavin production.},
	language = {EN},
	number = {6A},
	urldate = {2019-05-21},
	journal = {The Annals of Statistics},
	author = {Maathuis, Marloes H. and Kalisch, Markus and Bühlmann, Peter},
	month = dec,
	year = {2009},
	mrnumber = {MR2549555},
	zmnumber = {1191.62118},
	keywords = {sparsity, Causal analysis, directed acyclic graph (DAG), graphical modeling, intervention calculus, PC-algorithm},
	pages = {3133--3164},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/X3Q5F5VH/Maathuis et al. - 2009 - Estimating high-dimensional intervention effects f.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/XNRZYFY5/1250515382.html:text/html}
}

@article{sachs_causal_2005,
	title = {Causal {Protein}-{Signaling} {Networks} {Derived} from {Multiparameter} {Single}-{Cell} {Data}},
	volume = {308},
	copyright = {American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/308/5721/523},
	doi = {10.1126/science.1105809},
	abstract = {Machine learning was applied for the automated derivation of causal influences in cellular signaling networks. This derivation relied on the simultaneous measurement of multiple phosphorylated protein and phospholipid components in thousands of individual primary human immune system cells. Perturbing these cells with molecular interventions drove the ordering of connections between pathway components, wherein Bayesian network computational methods automatically elucidated most of the traditionally reported signaling relationships and predicted novel interpathway network causalities, which we verified experimentally. Reconstruction of network models from physiologically relevant primary single cells might be applied to understanding native-state tissue signaling biology, complex drug actions, and dysfunctional signaling in diseased cells.
Probabilistic analysis of the biochemical consequences of immune cell stimulation allows construction of causal signaling networks and prediction of new relationships.
Probabilistic analysis of the biochemical consequences of immune cell stimulation allows construction of causal signaling networks and prediction of new relationships.},
	language = {en},
	number = {5721},
	urldate = {2019-10-08},
	journal = {Science},
	author = {Sachs, Karen and Perez, Omar and Pe'er, Dana and Lauffenburger, Douglas A. and Nolan, Garry P.},
	month = apr,
	year = {2005},
	pmid = {15845847},
	pages = {523--529},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/VZ6QGNZV/Sachs et al. - 2005 - Causal Protein-Signaling Networks Derived from Mul.pdf:application/pdf}
}

@article{imbens_identification_1994,
	title = {Identification and {Estimation} of {Local} {Average} {Treatment} {Effects}},
	volume = {62},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/2951620},
	doi = {10.2307/2951620},
	number = {2},
	urldate = {2019-02-05},
	journal = {Econometrica},
	author = {Imbens, Guido W. and Angrist, Joshua D.},
	year = {1994},
	pages = {467--475}
}

@article{carneiro_evaluating_2010,
	title = {Evaluating {Marginal} {Policy} {Changes} and the {Average} {Effect} of {Treatment} for {Individuals} at the {Margin}},
	volume = {78},
	copyright = {© 2010 The Econometric Society},
	issn = {1468-0262},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA7089},
	doi = {10.3982/ECTA7089},
	abstract = {This paper develops methods for evaluating marginal policy changes. We characterize how the effects of marginal policy changes depend on the direction of the policy change, and show that marginal policy effects are fundamentally easier to identify and to estimate than conventional treatment parameters. We develop the connection between marginal policy effects and the average effect of treatment for persons on the margin of indifference between participation in treatment and nonparticipation, and use this connection to analyze both parameters. We apply our analysis to estimate the effect of marginal changes in tuition on the return to going to college.},
	language = {en},
	number = {1},
	urldate = {2019-02-06},
	journal = {Econometrica},
	author = {Carneiro, Pedro and Heckman, James J. and Vytlacil, Edward},
	year = {2010},
	keywords = {average marginal treatment effect, effects of marginal policy changes, marginal policy relevant treatment effect, Marginal treatment effect},
	pages = {377--394},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/IR869UEY/Carneiro et al. - 2010 - Evaluating Marginal Policy Changes and the Average.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/QIQALWGZ/ECTA7089.html:text/html}
}

@book{angrist_mastering_2014,
	address = {Princeton ; Oxford},
	edition = {with French flaps edition},
	title = {Mastering '{Metrics}: {The} {Path} from {Cause} to {Effect}},
	isbn = {978-0-691-15284-4},
	shorttitle = {Mastering '{Metrics}},
	abstract = {Applied econometrics, known to aficionados as 'metrics, is the original data science. 'Metrics encompasses the statistical methods economists use to untangle cause and effect in human affairs. Through accessible discussion and with a dose of kung fu–themed humor, Mastering 'Metrics presents the essential tools of econometric research and demonstrates why econometrics is exciting and useful.The five most valuable econometric methods, or what the authors call the Furious Five--random assignment, regression, instrumental variables, regression discontinuity designs, and differences in differences--are illustrated through well-crafted real-world examples (vetted for awesomeness by Kung Fu Panda's Jade Palace). Does health insurance make you healthier? Randomized experiments provide answers. Are expensive private colleges and selective public high schools better than more pedestrian institutions? Regression analysis and a regression discontinuity design reveal the surprising truth. When private banks teeter, and depositors take their money and run, should central banks step in to save them? Differences-in-differences analysis of a Depression-era banking crisis offers a response. Could arresting O. J. Simpson have saved his ex-wife's life? Instrumental variables methods instruct law enforcement authorities in how best to respond to domestic abuse.Wielding econometric tools with skill and confidence, Mastering 'Metrics uses data and statistics to illuminate the path from cause to effect.Shows why econometrics is importantExplains econometric research through humorous and accessible discussionOutlines empirical methods central to modern econometric practiceWorks through interesting and relevant real-world examples},
	language = {English},
	publisher = {Princeton University Press},
	author = {Angrist, Joshua D. and Pischke, Jörn-Steffen},
	month = dec,
	year = {2014}
}

@book{joyce_foundations_1999,
	address = {Cambridge ; New York},
	title = {The {Foundations} of {Causal} {Decision} {Theory}},
	isbn = {978-0-521-64164-7},
	abstract = {This book defends the view that any adequate account of rational decision making must take a decision maker's beliefs about causal relations into account. The early chapters of the book introduce the nonspecialist to the rudiments of expected utility theory. The major technical advance offered by the book is a "representation theorem" that shows that both causal decision theory and its main rival, Richard Jeffrey's logic of decision, are both instances of a more general conditional decision theory. In providing the most complete and robust defense of causal decision theory the book will be of interest to a broad range of readers in philosophy, economics, psychology, mathematics, and artificial intelligence.},
	language = {English},
	publisher = {Cambridge University Press},
	author = {Joyce, James M.},
	month = apr,
	year = {1999}
}

@article{hernan_does_2008,
	title = {Does obesity shorten life? {The} importance of well-defined interventions to answer causal questions},
	volume = {32},
	copyright = {2008 Nature Publishing Group},
	issn = {1476-5497},
	shorttitle = {Does obesity shorten life?},
	url = {https://www.nature.com/articles/ijo200882},
	doi = {10.1038/ijo.2008.82},
	abstract = {Many observational studies have estimated a strong effect of obesity on mortality. In this paper, we explicitly define the causal question that is asked by these studies and discuss the problems associated with it. We argue that observational studies of obesity and mortality violate the condition of consistency of counterfactual (potential) outcomes, a necessary condition for meaningful causal inference, because (1) they do not explicitly specify the interventions on body mass index (BMI) that are being compared and (2) different methods to modify BMI may lead to different counterfactual mortality outcomes, even if they lead to the same BMI value in a given person. Besides precluding the estimation of unambiguous causal effects, this violation of consistency affects the ability to address two additional conditions that are also necessary for causal inference: exchangeability and positivity. We conclude that consistency violations not only preclude the estimation of well-defined causal effects but also compromise our ability to estimate ill-defined causal effects.},
	language = {en},
	number = {S3},
	urldate = {2019-07-31},
	journal = {International Journal of Obesity},
	author = {Hernán, M. A. and Taubman, S. L.},
	month = aug,
	year = {2008},
	pages = {S8--S14},
	file = {Full Text PDF:/home/david/Zotero/storage/MRR58PFI/Hernán and Taubman - 2008 - Does obesity shorten life The importance of well-.pdf:application/pdf;Snapshot:/home/david/Zotero/storage/7BXSYE7S/ijo200882.html:text/html}
}


@article{peters_causal_2016,
	title = {Causal inference by using invariant prediction: identification and confidence intervals},
	volume = {78},
	copyright = {© 2016 Royal Statistical Society},
	issn = {1467-9868},
	shorttitle = {Causal inference by using invariant prediction},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12167},
	doi = {10.1111/rssb.12167},
	abstract = {What is the difference between a prediction that is made with a causal model and that with a non-causal model? Suppose that we intervene on the predictor variables or change the whole environment. The predictions from a causal model will in general work as well under interventions as for observational data. In contrast, predictions from a non-causal model can potentially be very wrong if we actively intervene on variables. Here, we propose to exploit this invariance of a prediction under a causal model for causal inference: given different experimental settings (e.g. various interventions) we collect all models that do show invariance in their predictive accuracy across settings and interventions. The causal model will be a member of this set of models with high probability. This approach yields valid confidence intervals for the causal relationships in quite general scenarios. We examine the example of structural equation models in more detail and provide sufficient assumptions under which the set of causal predictors becomes identifiable. We further investigate robustness properties of our approach under model misspecification and discuss possible extensions. The empirical properties are studied for various data sets, including large-scale gene perturbation experiments.},
	language = {en},
	number = {5},
	urldate = {2019-10-05},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Peters, Jonas and Bühlmann, Peter and Meinshausen, Nicolai},
	year = {2016},
	keywords = {Causal discovery, Causal inference, Confidence intervals, Invariant prediction},
	pages = {947--1012},
	file = {Full Text PDF:/home/david/Zotero/storage/GXV8FELN/Peters et al. - 2016 - Causal inference by using invariant prediction id.pdf:application/pdf;Snapshot:/home/david/Zotero/storage/D9QGYQLQ/rssb.html:text/html}
}


@article{arjovsky_invariant_2019,
	title = {Invariant {Risk} {Minimization}},
	url = {http://arxiv.org/abs/1907.02893},
	abstract = {We introduce Invariant Risk Minimization (IRM), a learning paradigm to estimate invariant correlations across multiple training distributions. To achieve this goal, IRM learns a data representation such that the optimal classifier, on top of that data representation, matches for all training distributions. Through theory and experiments, we show how the invariances learned by IRM relate to the causal structures governing the data and enable out-of-distribution generalization.},
	urldate = {2019-10-05},
	journal = {arXiv:1907.02893 [cs, stat]},
	author = {Arjovsky, Martin and Bottou, Léon and Gulrajani, Ishaan and Lopez-Paz, David},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.02893},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning}
}


@article{heckman_policy-relevant_2001,
	title = {Policy-{Relevant} {Treatment} {Effects}},
	volume = {91},
	issn = {0002-8282},
	url = {https://www.jstor.org/stable/2677742},
	number = {2},
	urldate = {2018-12-19},
	journal = {The American Economic Review},
	author = {Heckman, James J. and Vytlacil, Edward},
	year = {2001},
	pages = {107--111}
}

@article{shrier_intention--treat_2017,
	title = {The {Intention}-to-{Treat} {Analysis} {Is} {Not} {Always} the {Conservative} {Approach}},
	volume = {130},
	issn = {1555-7162},
	doi = {10.1016/j.amjmed.2017.03.023},
	language = {eng},
	number = {7},
	journal = {The American Journal of Medicine},
	author = {Shrier, Ian and Verhagen, Evert and Stovitz, Steven D.},
	month = jul,
	year = {2017},
	pmid = {28392186},
	keywords = {Humans, Intention to Treat Analysis, Research Design},
	pages = {867--871}
}

@article{le_cam_comparison_1996,
	title = {Comparison of {Experiments} - {A} {Short} {Review}.pdf},
	volume = {30},
	urldate = {2018-02-15},
	journal = {IMS  Lecture  Notes  - Monograph  Series},
	author = {Le Cam, L.},
	year = {1996},
	file = {Comparison of Experiments - A Short Review.pdf:/home/users/u4533535/Zotero/storage/LF42SGNQ/Comparison of Experiments - A Short Review.pdf:application/pdf}
}

@incollection{morris_david_2019,
	edition = {Summer 2019},
	title = {David {Hume}},
	url = {https://plato.stanford.edu/archives/sum2019/entries/hume/},
	abstract = {Generally regarded as one of the most important philosophers to writein English, David Hume (1711–1776) was also well known in hisown time as an historian and essayist. A master stylist in any genre,his major philosophical works—A Treatise of HumanNature (1739–1740), the Enquiries concerning HumanUnderstanding (1748) and concerning the Principles ofMorals (1751), as well as his posthumously publishedDialogues concerning Natural Religion (1779)—remainwidely and deeply influential., Although Hume’s more conservative contemporaries denounced hiswritings as works of scepticism and atheism, his influence is evidentin the moral philosophy and economic writings of his close friend AdamSmith. Kant reported that Hume’s work woke him from his“dogmatic slumbers”  andJeremy Bentham remarked that reading Hume “caused the scales tofall” from his eyes. Charles Darwin regarded his work as acentral influence on the theory of evolution. The diverse directionsin which these writers took what they gleaned from reading him reflectboth the richness of their sources and the wide range of hisempiricism. Today, philosophers recognize Hume as a thoroughgoingexponent of philosophical naturalism, as a precursor of contemporarycognitive science, and as the inspiration for several of the mostsignificant types of ethical theory developed in contemporary moralphilosophy.},
	urldate = {2019-09-24},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Morris, William Edward and Brown, Charlotte R.},
	editor = {Zalta, Edward N.},
	year = {2019},
	keywords = {Berkeley, George, Clarke, Samuel, free rider problem, Hobbes, Thomas, Hume, David: Newtonianism and Anti-Newtonianism, Locke, John, miracles, Scottish Philosophy: in the 18th Century}
}

@article{cartwright_causal_1979,
	title = {Causal {Laws} and {Effective} {Strategies}},
	volume = {13},
	issn = {0029-4624},
	url = {https://www.jstor.org/stable/2215337},
	doi = {10.2307/2215337},
	number = {4},
	urldate = {2019-09-23},
	journal = {Noûs},
	author = {Cartwright, Nancy},
	year = {1979},
	pages = {419--437}
}

@book{tao_introduction_2011,
	title = {An {Introduction} to {Measure} {Theory}},
	isbn = {978-0-8218-6919-2},
	abstract = {This is a graduate text introducing the fundamentals of measure theory and integration theory, which is the foundation of modern real analysis. The text focuses first on the concrete setting of Lebesgue measure and the Lebesgue integral (which in turn is motivated by the more classical concepts of Jordan measure and the Riemann integral), before moving on to abstract measure and integration theory, including the standard convergence theorems, Fubini\&\#39;s theorem, and the Caratheodory extension theorem. Classical differentiation theorems, such as the Lebesgue and Rademacher differentiation theorems, are also covered, as are connections with probability theory. The material is intended to cover a quarter or semester\&\#39;s worth of material for a first graduate course in real analysis. There is an emphasis in the text on tying together the abstract and the concrete sides of the subject, using the latter to illustrate and motivate the former. The central role of key principles (such as Littlewood\&\#39;s three principles) as providing guiding intuition to the subject is also emphasized. There are a large number of exercises throughout that develop key aspects of the theory, and are thus an integral component of the text. As a supplementary section, a discussion of general problem-solving strategies in analysis is also given. The last three sections discuss optional topics related to the main matter of the book.},
	language = {en},
	publisher = {American Mathematical Soc.},
	author = {Tao, Terence},
	month = sep,
	year = {2011},
	note = {Google-Books-ID: HoGDAwAAQBAJ},
	keywords = {Mathematics / General}
}
@incollection{kissinger_abstract_2014,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Abstract {Tensor} {Systems} as {Monoidal} {Categories}},
	isbn = {978-3-642-54789-8},
	url = {https://doi.org/10.1007/978-3-642-54789-8_13},
	abstract = {The primary contribution of this paper is to give a formal, categorical treatment to Penrose’s abstract tensor notation, in the context of traced symmetric monoidal categories. To do so, we introduce a typed, sum-free version of an abstract tensor system and demonstrate the construction of its associated category. We then show that the associated category of the free abstract tensor system is in fact the free traced symmetric monoidal category on a monoidal signature. A notable consequence of this result is a simple proof for the soundness and completeness of the diagrammatic language for traced symmetric monoidal categories.},
	language = {en},
	urldate = {2019-08-14},
	booktitle = {Categories and {Types} in {Logic}, {Language}, and {Physics}: {Essays} {Dedicated} to {Jim} {Lambek} on the {Occasion} of {His} 90th {Birthday}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kissinger, Aleks},
	editor = {Casadio, Claudia and Coecke, Bob and Moortgat, Michael and Scott, Philip},
	year = {2014},
	doi = {10.1007/978-3-642-54789-8_13},
	keywords = {Canonical Label, Lower Label, Monoidal Category, Monoidal Functor, Symmetric Monoidal Category},
	pages = {235--252},
	file = {Springer Full Text PDF:/home/users/u4533535/Zotero/storage/E5FRGNLX/Kissinger - 2014 - Abstract Tensor Systems as Monoidal Categories.pdf:application/pdf}
}

@article{clerc_pointless_2017,
	title = {Pointless learning},
	url = {https://www.research.ed.ac.uk/portal/en/publications/pointless-learning(694fb610-69c5-469c-9793-825df4f8ddec).html},
	doi = {10.1007/978-3-662-54458-7_21},
	abstract = {Description},
	language = {English},
	urldate = {2018-03-20},
	journal = {20th International Conference on Foundations of Software Science and Computation Structures (FoSSaCS 2017)},
	author = {Clerc, Florence and Dahlqvist, Fredrik and Danos, Vincent and Garnier, Ilias},
	month = mar,
	year = {2017},
	file = {Full Text PDF:/home/david/Zotero/storage/R6QHQVFC/Clerc et al. - 2017 - Pointless learning.pdf:application/pdf;Snapshot:/home/david/Zotero/storage/FJ28CGHI/pointless-learning(694fb610-69c5-469c-9793-825df4f8ddec).html:text/html}
}

@article{selinger_survey_2010,
	title = {A survey of graphical languages for monoidal categories},
	volume = {813},
	url = {http://arxiv.org/abs/0908.3347},
	doi = {10.1007/978-3-642-12821-9_4},
	abstract = {This article is intended as a reference guide to various notions of monoidal categories and their associated string diagrams. It is hoped that this will be useful not just to mathematicians, but also to physicists, computer scientists, and others who use diagrammatic reasoning. We have opted for a somewhat informal treatment of topological notions, and have omitted most proofs. Nevertheless, the exposition is sufficiently detailed to make it clear what is presently known, and to serve as a starting place for more in-depth study. Where possible, we provide pointers to more rigorous treatments in the literature. Where we include results that have only been proved in special cases, we indicate this in the form of caveats.},
	urldate = {2019-08-07},
	journal = {arXiv:0908.3347 [math]},
	author = {Selinger, Peter},
	year = {2010},
	note = {arXiv: 0908.3347},
	keywords = {18D10, Mathematics - Category Theory},
	pages = {289--355},
	file = {arXiv\:0908.3347 PDF:/home/david/Zotero/storage/NKS6X5MX/Selinger - 2010 - A survey of graphical languages for monoidal categ.pdf:application/pdf;arXiv.org Snapshot:/home/david/Zotero/storage/9HVYKYBC/0908.html:text/html}
}


@article{fong_causal_2013,
	title = {Causal {Theories}: {A} {Categorical} {Perspective} on {Bayesian} {Networks}},
	shorttitle = {Causal {Theories}},
	url = {http://arxiv.org/abs/1301.6201},
	abstract = {In this dissertation we develop a new formal graphical framework for causal reasoning. Starting with a review of monoidal categories and their associated graphical languages, we then revisit probability theory from a categorical perspective and introduce Bayesian networks, an existing structure for describing causal relationships. Motivated by these, we propose a new algebraic structure, which we term a causal theory. These take the form of a symmetric monoidal category, with the objects representing variables and morphisms ways of deducing information about one variable from another. A major advantage of reasoning with these structures is that the resulting graphical representations of morphisms match well with intuitions for flows of information between these variables. These categories can then be modelled in other categories, providing concrete interpretations for the variables and morphisms. In particular, we shall see that models in the category of measurable spaces and stochastic maps provide a slight generalisation of Bayesian networks, and naturally form a category themselves. We conclude with a discussion of this category, classifying the morphisms and discussing some basic universal constructions. ERRATA: (i) Pages 41-42: Objects of a causal theory are words, not collections, in \$V\$, and we include swaps as generating morphisms, subject to the identities defining a symmetric monoidal category. (ii) Page 46: A causal model is a strong symmetric monoidal functor.},
	urldate = {2018-08-08},
	journal = {arXiv:1301.6201 [math]},
	author = {Fong, Brendan},
	month = jan,
	year = {2013},
	note = {arXiv: 1301.6201},
	keywords = {Mathematics - Probability},
	annote = {Comment: 72 pages},
	file = {arXiv\:1301.6201 PDF:/home/david/Zotero/storage/ZVU7GY99/Fong - 2013 - Causal Theories A Categorical Perspective on Baye.pdf:application/pdf;arXiv.org Snapshot:/home/david/Zotero/storage/YAUZUKYJ/1301.html:text/html}
}


@article{cho_disintegration_2019,
	title = {Disintegration and {Bayesian} inversion via string diagrams},
	volume = {29},
	issn = {0960-1295, 1469-8072},
	doi = {10.1017/S0960129518000488},
	abstract = {The notions of disintegration and Bayesian inversion are fundamental in conditional probability theory. They produce channels, as conditional probabilities, from a joint state, or from an already given channel (in opposite direction). These notions exist in the literature, in concrete situations, but are presented here in abstract graphical formulations. The resulting abstract descriptions are used for proving basic results in conditional probability theory. The existence of disintegration and Bayesian inversion is discussed for discrete probability, and also for measure-theoretic probability – via standard Borel spaces and via likelihoods. Finally, the usefulness of disintegration and Bayesian inversion is illustrated in several examples.},
	language = {en},
	number = {7},
	urldate = {2019-08-07},
	journal = {Mathematical Structures in Computer Science},
	author = {Cho, Kenta and Jacobs, Bart},
	month = aug,
	year = {2019},
	keywords = {Bayesian inversion, Conditional probability, disintegration, monoidal category, string diagram},
	pages = {938--971},
}


@inproceedings{jacobs_causal_2019,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Causal {Inference} by {String} {Diagram} {Surgery}},
	isbn = {978-3-030-17127-8},
	abstract = {Extracting causal relationships from observed correlations is a growing area in probabilistic reasoning, originating with the seminal work of Pearl and others from the early 1990s. This paper develops a new, categorically oriented view based on a clear distinction between syntax (string diagrams) and semantics (stochastic matrices), connected via interpretations as structure-preserving functors.A key notion in the identification of causal effects is that of an intervention, whereby a variable is forcefully set to a particular value independent of any prior dependencies. We represent the effect of such an intervention as an endofunctor which performs ‘string diagram surgery’ within the syntactic category of string diagrams. This diagram surgery in turn yields a new, interventional distribution via the interpretation functor. While in general there is no way to compute interventional distributions purely from observed data, we show that this is possible in certain special cases using a calculational tool called comb disintegration.We showcase this technique on a well-known example, predicting the causal effect of smoking on cancer in the presence of a confounding common cause. We then conclude by showing that this technique provides simple sufficient conditions for computing interventions which apply to a wide variety of situations considered in the causal inference literature.},
	language = {en},
	booktitle = {Foundations of {Software} {Science} and {Computation} {Structures}},
	publisher = {Springer International Publishing},
	author = {Jacobs, Bart and Kissinger, Aleks and Zanasi, Fabio},
	editor = {Bojańczyk, Mikołaj and Simpson, Alex},
	year = {2019},
	keywords = {Causality, Probabilistic reasoning, String diagrams},
	pages = {313--329},
	file = {Springer Full Text PDF:/home/david/Zotero/storage/HT33EN7P/Jacobs et al. - 2019 - Causal Inference by String Diagram Surgery.pdf:application/pdf}
}

@article{jacobs_probability_2018,
	title = {From probability monads to commutative effectuses},
	volume = {94},
	issn = {2352-2208},
	url = {http://www.sciencedirect.com/science/article/pii/S2352220816301122},
	doi = {10.1016/j.jlamp.2016.11.006},
	abstract = {Effectuses have recently been introduced as categorical models for quantum computation, with probabilistic and Boolean (classical) computation as special cases. These ‘probabilistic’ models are called commutative effectuses, and are the focus of attention here. The paper describes the main known ‘probability’ monads: the monad of discrete probability measures, the Giry monad, the expectation monad, the probabilistic power domain monad, the Radon monad, and the Kantorovich monad. It also introduces successive properties that a monad should satisfy so that its Kleisli category is a commutative effectus. The main properties are: partial additivity, strong affineness, and commutativity. It is shown that the resulting commutative effectus provides a categorical model of probability theory, including a logic using effect modules with parallel and sequential conjunction, predicate- and state-transformers, normalisation and conditioning of states.},
	urldate = {2019-08-07},
	journal = {Journal of Logical and Algebraic Methods in Programming},
	author = {Jacobs, Bart},
	month = jan,
	year = {2018},
	pages = {200--237},
	file = {ScienceDirect Full Text PDF:/home/david/Zotero/storage/ED644A5W/Jacobs - 2018 - From probability monads to commutative effectuses.pdf:application/pdf;ScienceDirect Snapshot:/home/david/Zotero/storage/2ZG8CF8G/S2352220816301122.html:text/html}
}

@book{hernan_causal_2018,
	title = {Causal {Inference}},
	language = {en-us},
	publisher = {Chapman \& Hall/CRC},
	author = {Hernán, MA and Robins, JM},
	year = {2018},
	file = {Snapshot:/home/users/u4533535/Zotero/storage/3PD2MVZA/causal-inference-book.html:text/html}
}

@article{bengio_meta-transfer_2019,
	title = {A {Meta}-{Transfer} {Objective} for {Learning} to {Disentangle} {Causal} {Mechanisms}},
	url = {http://arxiv.org/abs/1901.10912},
	abstract = {We propose to meta-learn causal structures based on how fast a learner adapts to new distributions arising from sparse distributional changes, e.g. due to interventions, actions of agents and other sources of non-stationarities. We show that under this assumption, the correct causal structural choices lead to faster adaptation to modified distributions because the changes are concentrated in one or just a few mechanisms when the learned knowledge is modularized appropriately. This leads to sparse expected gradients and a lower effective number of degrees of freedom needing to be relearned while adapting to the change. It motivates using the speed of adaptation to a modified distribution as a meta-learning objective. We demonstrate how this can be used to determine the cause-effect relationship between two observed variables. The distributional changes do not need to correspond to standard interventions (clamping a variable), and the learner has no direct knowledge of these interventions. We show that causal structures can be parameterized via continuous variables and learned end-to-end. We then explore how these ideas could be used to also learn an encoder that would map low-level observed variables to unobserved causal variables leading to faster adaptation out-of-distribution, learning a representation space where one can satisfy the assumptions of independent mechanisms and of small and sparse changes in these mechanisms due to actions and non-stationarities.},
	urldate = {2019-05-22},
	journal = {arXiv:1901.10912 [cs, stat]},
	author = {Bengio, Yoshua and Deleu, Tristan and Rahaman, Nasim and Ke, Rosemary and Lachapelle, Sébastien and Bilaniuk, Olexa and Goyal, Anirudh and Pal, Christopher},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.10912},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv\:1901.10912 PDF:/home/users/u4533535/Zotero/storage/PSCL26YP/Bengio et al. - 2019 - A Meta-Transfer Objective for Learning to Disentan.pdf:application/pdf}
}

@article{bongers_theoretical_2016,
	title = {Theoretical {Aspects} of {Cyclic} {Structural} {Causal} {Models}},
	url = {http://arxiv.org/abs/1611.06221},
	abstract = {Structural causal models (SCMs), also known as (non-parametric) structural equation models (SEMs), are widely used for causal modeling purposes. A large body of theoretical results is available for the special case in which cycles are absent (i.e., acyclic SCMs, also known as recursive SEMs). However, in many application domains cycles are abundantly present, for example in the form of feedback loops. In this paper, we provide a general and rigorous theory of cyclic SCMs. The paper consists of two parts: the first part gives a rigorous treatment of structural causal models, dealing with measure-theoretic and other complications that arise in the presence of cycles. In contrast with the acyclic case, in cyclic SCMs solutions may no longer exist, or if they exist, they may no longer be unique, or even measurable in general. We give several sufficient and necessary conditions for the existence of (unique) measurable solutions. We show how causal reasoning proceeds in these models and how this differs from the acyclic case. Moreover, we give an overview of the Markov properties that hold for cyclic SCMs. In the second part, we address the question of how one can marginalize an SCM (possibly with cycles) to a subset of the endogenous variables. We show that under a certain condition, one can effectively remove a subset of the endogenous variables from the model, leading to a more parsimonious marginal SCM that preserves the causal and counterfactual semantics of the original SCM on the remaining variables. Moreover, we show how the marginalization relates to the latent projection and to latent confounders, i.e. latent common causes.},
	urldate = {2019-02-06},
	journal = {arXiv:1611.06221 [cs, stat]},
	author = {Bongers, Stephan and Peters, Jonas and Schölkopf, Bernhard and Mooij, Joris M.},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.06221},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Methodology, Computer Science - Machine Learning},
	annote = {Comment: Will probably be submitted to The Annals of Statistics},
	file = {arXiv\:1611.06221 PDF:/home/users/u4533535/Zotero/storage/BIBWS6N9/Bongers et al. - 2016 - Theoretical Aspects of Cyclic Structural Causal Mo.pdf:application/pdf;arXiv.org Snapshot:/home/users/u4533535/Zotero/storage/F36XBBPJ/1611.html:text/html}
}

@article{rubin_causal_2005,
	title = {Causal {Inference} {Using} {Potential} {Outcomes}},
	volume = {100},
	issn = {0162-1459},
	url = {https://doi.org/10.1198/016214504000001880},
	doi = {10.1198/016214504000001880},
	abstract = {Causal effects are defined as comparisons of potential outcomes under different treatments on a common set of units. Observed values of the potential outcomes are revealed by the assignment mechanism—a probabilistic model for the treatment each unit receives as a function of covariates and potential outcomes. Fisher made tremendous contributions to causal inference through his work on the design of randomized experiments, but the potential outcomes perspective applies to other complex experiments and nonrandomized studies as well. As noted by Kempthorne in his 1976 discussion of Savage's Fisher lecture, Fisher never bridged his work on experimental design and his work on parametric modeling, a bridge that appears nearly automatic with an appropriate view of the potential outcomes framework, where the potential outcomes and covariates are given a Bayesian distribution to complete the model specification. Also, this framework crisply separates scientific inference for causal effects and decisions based on such inference, a distinction evident in Fisher's discussion of tests of significance versus tests in an accept/reject framework. But Fisher never used the potential outcomes framework, originally proposed by Neyman in the context of randomized experiments, and as a result he provided generally flawed advice concerning the use of the analysis of covariance to adjust for posttreatment concomitants in randomized trials.},
	number = {469},
	urldate = {2018-07-09},
	journal = {Journal of the American Statistical Association},
	author = {Rubin, Donald B.},
	month = mar,
	year = {2005},
	keywords = {Analysis of covariance, Assignment mechanism, Assignment-based causal inference, Bayesian inference, Direct causal effects, Fieller–Creasy, Fisher, Neyman, Observational studies, Principal stratification, Randomized experiments, Rubin causal model},
	pages = {322--331},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/UCYCX9EZ/Rubin - 2005 - Causal Inference Using Potential Outcomes.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/FL3D7Q29/016214504000001880.html:text/html}
}

@article{maathuis_predicting_2010,
	title = {Predicting causal effects in large-scale systems from observational data},
	volume = {7},
	copyright = {2010 Nature Publishing Group},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth0410-247},
	doi = {10.1038/nmeth0410-247},
	abstract = {Predicting causal effects in large-scale systems from observational data},
	language = {en},
	number = {4},
	urldate = {2019-02-07},
	journal = {Nature Methods},
	author = {Maathuis, Marloes H. and Colombo, Diego and Kalisch, Markus and Bühlmann, Peter},
	month = apr,
	year = {2010},
	pages = {247--248},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/HNZXCRU9/Maathuis et al. - 2010 - Predicting causal effects in large-scale systems f.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/KEPIAZGD/nmeth0410-247.html:text/html}
}

@article{maathuis_estimating_2009,
	title = {Estimating high-dimensional intervention effects from observational data},
	volume = {37},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/euclid.aos/1250515382},
	doi = {10.1214/09-AOS685},
	abstract = {We assume that we have observational data generated from an unknown underlying directed acyclic graph (DAG) model. A DAG is typically not identifiable from observational data, but it is possible to consistently estimate the equivalence class of a DAG. Moreover, for any given DAG, causal effects can be estimated using intervention calculus. In this paper, we combine these two parts. For each DAG in the estimated equivalence class, we use intervention calculus to estimate the causal effects of the covariates on the response. This yields a collection of estimated causal effects for each covariate. We show that the distinct values in this set can be consistently estimated by an algorithm that uses only local information of the graph. This local approach is computationally fast and feasible in high-dimensional problems. We propose to use summary measures of the set of possible causal effects to determine variable importance. In particular, we use the minimum absolute value of this set, since that is a lower bound on the size of the causal effect. We demonstrate the merits of our methods in a simulation study and on a data set about riboflavin production.},
	language = {EN},
	number = {6A},
	urldate = {2019-05-21},
	journal = {The Annals of Statistics},
	author = {Maathuis, Marloes H. and Kalisch, Markus and Bühlmann, Peter},
	month = dec,
	year = {2009},
	mrnumber = {MR2549555},
	zmnumber = {1191.62118},
	keywords = {Causal analysis, directed acyclic graph (DAG), graphical modeling, intervention calculus, PC-algorithm, sparsity},
	pages = {3133--3164},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/X3Q5F5VH/Maathuis et al. - 2009 - Estimating high-dimensional intervention effects f.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/XNRZYFY5/1250515382.html:text/html}
}

@article{fong_causal_2013,
	title = {Causal {Theories}: {A} {Categorical} {Perspective} on {Bayesian} {Networks}},
	shorttitle = {Causal {Theories}},
	url = {http://arxiv.org/abs/1301.6201},
	abstract = {In this dissertation we develop a new formal graphical framework for causal reasoning. Starting with a review of monoidal categories and their associated graphical languages, we then revisit probability theory from a categorical perspective and introduce Bayesian networks, an existing structure for describing causal relationships. Motivated by these, we propose a new algebraic structure, which we term a causal theory. These take the form of a symmetric monoidal category, with the objects representing variables and morphisms ways of deducing information about one variable from another. A major advantage of reasoning with these structures is that the resulting graphical representations of morphisms match well with intuitions for flows of information between these variables. These categories can then be modelled in other categories, providing concrete interpretations for the variables and morphisms. In particular, we shall see that models in the category of measurable spaces and stochastic maps provide a slight generalisation of Bayesian networks, and naturally form a category themselves. We conclude with a discussion of this category, classifying the morphisms and discussing some basic universal constructions. ERRATA: (i) Pages 41-42: Objects of a causal theory are words, not collections, in \$V\$, and we include swaps as generating morphisms, subject to the identities defining a symmetric monoidal category. (ii) Page 46: A causal model is a strong symmetric monoidal functor.},
	urldate = {2018-08-08},
	journal = {arXiv:1301.6201 [math]},
	author = {Fong, Brendan},
	month = jan,
	year = {2013},
	note = {arXiv: 1301.6201},
	keywords = {Mathematics - Probability},
	annote = {Comment: 72 pages},
	file = {arXiv\:1301.6201 PDF:/home/users/u4533535/Zotero/storage/ZVU7GY99/Fong - 2013 - Causal Theories A Categorical Perspective on Baye.pdf:application/pdf;arXiv.org Snapshot:/home/users/u4533535/Zotero/storage/YAUZUKYJ/1301.html:text/html}
}

@book{collaboration_cochrane_nodate,
	title = {Cochrane Handbook for Systematic Reviews of Interventions Version 5.1.0},
	author = {Higgins, JPT and Green, S},
	pages = {241},
	year = {2011},
	publisher = {The Cochrane Collaboration}
}

@book{cartwright_no_1994,
	title = {No {Causes} in, {No} {Causes} out},
	isbn = {978-0-19-159716-9},
	url = {https://www.oxfordscholarship.com/view/10.1093/0198235070.001.0001/acprof-9780198235071-chapter-3},
	abstract = {This chapter argues that one cannot get knowledge of causes from equations and associations alone, using critical analyses of theoretical examples in physics and of attempts in the philosophy of science and economics (e.g. Granger causality and various probabilistic theories of causality) to reduce causal claims to probabilities. Old causal knowledge must be supplied for new causal knowledge to be had. Analysis of experimental methods and actual experiments (Stanford Gravity Probe) show how this can be done.},
	language = {en\_US},
	urldate = {2019-05-21},
	publisher = {Oxford University Press},
	author = {Cartwright, Nancy},
	month = apr,
	year = {1994},
	file = {Snapshot:/home/users/u4533535/Zotero/storage/ME84AMGS/acprof-9780198235071-chapter-3.html:text/html}
}

@article{mansournia_biases_2017,
	title = {Biases in randomized trials: a conversation between trialists and epidemiologists},
	volume = {28},
	issn = {1044-3983},
	shorttitle = {Biases in randomized trials},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5130591/},
	doi = {10.1097/EDE.0000000000000564},
	abstract = {Trialists and epidemiologists often employ different terminology to refer to biases in randomized trials and observational studies, even though many biases have a similar structure in both types of study. We use causal diagrams to represent the structure of biases, as described by the Cochrane Collaboration for randomized trials, and provide a translation to the usual epidemiologic terms of confounding, selection bias, and measurement bias. This structural approach clarifies that an explicit description of the inferential goal—the intention-to-treat effect or the per-protocol effect—is necessary to assess risk of bias in the estimates. Being aware of each other's terminologies will enhance communication between trialists and epidemiologists when considering key concepts and methods for causal inference.},
	number = {1},
	urldate = {2019-05-21},
	journal = {Epidemiology (Cambridge, Mass.)},
	author = {Mansournia, Mohammad Ali and Higgins, Julian P. T. and Sterne, Jonathan A. C. and Hernán, Miguel A.},
	month = jan,
	year = {2017},
	pmid = {27748683},
	pmcid = {PMC5130591},
	pages = {54--59},
	file = {PubMed Central Full Text PDF:/home/users/u4533535/Zotero/storage/YKY4QHUI/Mansournia et al. - 2017 - Biases in randomized trials a conversation betwee.pdf:application/pdf}
}

@book{angrist_mastering_2014,
	address = {Princeton ; Oxford},
	edition = {with French flaps edition},
	title = {Mastering '{Metrics}: {The} {Path} from {Cause} to {Effect}},
	isbn = {978-0-691-15284-4},
	shorttitle = {Mastering '{Metrics}},
	abstract = {Applied econometrics, known to aficionados as 'metrics, is the original data science. 'Metrics encompasses the statistical methods economists use to untangle cause and effect in human affairs. Through accessible discussion and with a dose of kung fu–themed humor, Mastering 'Metrics presents the essential tools of econometric research and demonstrates why econometrics is exciting and useful.The five most valuable econometric methods, or what the authors call the Furious Five--random assignment, regression, instrumental variables, regression discontinuity designs, and differences in differences--are illustrated through well-crafted real-world examples (vetted for awesomeness by Kung Fu Panda's Jade Palace). Does health insurance make you healthier? Randomized experiments provide answers. Are expensive private colleges and selective public high schools better than more pedestrian institutions? Regression analysis and a regression discontinuity design reveal the surprising truth. When private banks teeter, and depositors take their money and run, should central banks step in to save them? Differences-in-differences analysis of a Depression-era banking crisis offers a response. Could arresting O. J. Simpson have saved his ex-wife's life? Instrumental variables methods instruct law enforcement authorities in how best to respond to domestic abuse.Wielding econometric tools with skill and confidence, Mastering 'Metrics uses data and statistics to illuminate the path from cause to effect.Shows why econometrics is importantExplains econometric research through humorous and accessible discussionOutlines empirical methods central to modern econometric practiceWorks through interesting and relevant real-world examples},
	language = {English},
	publisher = {Princeton University Press},
	author = {Angrist, Joshua D. and Pischke, Jörn-Steffen},
	month = dec,
	year = {2014}
}


@article{lewis_causal_1981,
	title = {Causal decision theory},
	volume = {59},
	issn = {0004-8402},
	url = {https://doi.org/10.1080/00048408112340011},
	doi = {10.1080/00048408112340011},
	abstract = {Newcomb's problem and similar cases show the need to incorporate causal distinctions into the theory of rational decision; the usual noncausal decision theory, though simpler, does not always give the right answers. I give my own version of causal decision theory, compare it with versions offered by several other authors, and suggest that the versions have more in common than meets the eye.},
	number = {1},
	urldate = {2019-01-11},
	journal = {Australasian Journal of Philosophy},
	author = {Lewis, David},
	month = mar,
	year = {1981},
	pages = {5--30},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/64MDNVZU/Lewis - 1981 - Causal decision theory.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/J6VDENHW/00048408112340011.html:text/html}
}

@incollection{dawid_decision-theoretic_2012,
	title = {The {Decision}-{Theoretic} {Approach} to {Causal} {Inference}},
	copyright = {Copyright © 2012 John Wiley \& Sons, Ltd},
	isbn = {978-1-119-94571-0},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119945710.ch4},
	abstract = {This chapter contains sections titled: Introduction Decision theory and causality No confounding Confounding Propensity analysis Instrumental variable Effect of treatment of the treated Connections and contrasts Postscript Acknowledgements References},
	language = {en},
	urldate = {2019-05-16},
	booktitle = {Causality},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Dawid, Philip},
	year = {2012},
	doi = {10.1002/9781119945710.ch4},
	keywords = {‘propensity analysis’ and decision-theoretic version, algebraic theory of conditional independence, and potential response modelling and causal graphs, and the DT approach, causal and associational concepts and quantities, causal assertions as ECI relations, causal inference, causal inference problems, DT, DT explication of concept of ACE, DT specialisation, ECI with DAG-related, Fisherian/decision-theoretic approach, information transfer from one ‘regime’ to another, Pearlian, propensity, structure, variables and treatment effect},
	pages = {25--42}
}

@inproceedings{balke_counterfactual_1994,
	address = {San Francisco, CA, USA},
	series = {{UAI}'94},
	title = {Counterfactual {Probabilities}: {Computational} {Methods}, {Bounds} and {Applications}},
	isbn = {978-1-55860-332-5},
	shorttitle = {Counterfactual {Probabilities}},
	url = {http://dl.acm.org/citation.cfm?id=2074394.2074401},
	abstract = {Evaluation of counterfactual queries (e.g., "If A were true, would C have been true?") is important to fault diagnosis, planning, and determination of liability. In this paper we present methods for computing the probabilities of such queries using the formulation proposed in [Balke and Pearl, 1994], where the antecedent of the query is interpreted as an external action that forces the proposition A to be true. When a prior probability is available on the causal mechanisms governing the domain, counterfactual probabilities can be evaluated precisely. However, when causal knowledge is specified as conditional probabilities on the observables, only bounds can computed. This paper develops techniques for evaluating these bounds, and demonstrates their use in two applications: (1) the determination of treatment efficacy from studies in which subjects may choose their own treatment, and (2) the determination of liability in product-safety litigation.},
	urldate = {2019-05-15},
	booktitle = {Proceedings of the {Tenth} {International} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Balke, Alexander and Pearl, Judea},
	year = {1994},
	note = {event-place: Seattle, WA},
	pages = {46--54},
	file = {ACM Full Text PDF:/home/users/u4533535/Zotero/storage/G9MKC43K/Balke and Pearl - 1994 - Counterfactual Probabilities Computational Method.pdf:application/pdf}
}

@book{geneletti2007defining,
  title={Defining and identifying the effect of treatment on the treated},
  author={Geneletti, Sara and Dawid, A Philip},
  year={2007},
  publisher={Citeseer}
}


@article{rubin_estimating_1974,
	title = {Estimating causal effects of treatments in randomized and nonrandomized studies},
	volume = {66},
	issn = {1939-2176(Electronic),0022-0663(Print)},
	doi = {10.1037/h0037350},
	abstract = {Presents a discussion of matching, randomization, random sampling, and other methods of controlling extraneous variation. The objective was to specify the benefits of randomization in estimating causal effects of treatments. It is concluded that randomization should be employed whenever possible but that the use of carefully controlled nonrandomized data to estimate causal effects is a reasonable and necessary procedure in many cases. (15 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {5},
	journal = {Journal of Educational Psychology},
	author = {Rubin, Donald B.},
	year = {1974},
	keywords = {Experimental Design, Random Sampling},
	pages = {688--701},
	file = {Snapshot:/home/users/u4533535/Zotero/storage/SIQJIHE5/1975-06502-001.html:text/html}
}

@article{robins2010alternative,
  title={Alternative graphical causal models and the identification of direct effects},
  author={Robins, James M and Richardson, Thomas S},
  journal={Causality and psychopathology: Finding the determinants of disorders and their cures},
  pages={103--158},
  year={2010},
  publisher={Oxford University Press New York, NY}
}


@book{toutenburg_ferguson_1967,
	title = {Mathematical {Statistics}: {A} {Decision} {Theoretic} {Approach}},
	isbn = {978-1-4832-2123-6},
	shorttitle = {Mathematical {Statistics}},
	abstract = {Mathematical Statistics: A Decision Theoretic Approach presents an investigation of the extent to which problems of mathematical statistics may be treated by decision theory approach. This book deals with statistical theory that could be justified from a decision-theoretic viewpoint.Organized into seven chapters, this book begins with an overview of the elements of decision theory that are similar to those of the theory of games. This text then examines the main theorems of decision theory that involve two more notions, namely the admissibility of a decision rule and the completeness of a class of decision rules. Other chapters consider the development of theorems in decision theory that are valid in general situations. This book discusses as well the invariance principle that involves groups of transformations over the three spaces around which decision theory is built. The final chapter deals with sequential decision problems.This book is a valuable resource for first-year graduate students in mathematics.},
	language = {en},
	publisher = {Academic Press},
	author = {Ferguson, Thomas S.},
	month = jul,
	year = {1967},
	keywords = {Mathematics / Applied, Mathematics / Probability \& Statistics / General}
}

@article{hajek_what_2003,
	title = {What {Conditional} {Probability} {Could} {Not} {Be}},
	volume = {137},
	issn = {1573-0964},
	url = {https://doi.org/10.1023/B:SYNT.0000004904.91112.16},
	doi = {10.1023/B:SYNT.0000004904.91112.16},
	language = {en},
	number = {3},
	urldate = {2019-05-08},
	journal = {Synthese},
	author = {Hájek, Alan},
	month = dec,
	year = {2003},
	keywords = {Conditional Probability, Probability Assignment, Ratio Analysis, Trouble Spot, Unconditional Probability},
	pages = {273--323},
	file = {Springer Full Text PDF:/home/users/u4533535/Zotero/storage/E75VCTXL/Hájek - 2003 - What Conditional Probability Could Not Be.pdf:application/pdf}
}
@inproceedings{besserve_group_2017,
  title={Group invariance principles for causal generative models},
  author={Besserve, Michel and Schoelkopf, Bernhard and Janzing, Dominik and others},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={557--565},
  year={2018}
}


@inproceedings{peters_identifiability_2012,
  title={Identifiability of causal graphs using functional Models},
  author={Peters, Jonas and Mooij, Joris M and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  booktitle={Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
  pages={589--598},
  year={2011},
  organization={AUAI Press}
}


@inproceedings{tian2002general,
  title={A general identification condition for causal effects},
  author={Tian, Jin and Pearl, Judea},
  booktitle={Aaai/iaai},
  pages={567--573},
  year={2002},
  month={July}
}

@inproceedings{dawid_beware_2010,
	title = {Beware of the {DAG}!},
	url = {http://proceedings.mlr.press/v6/dawid10a.html},
	abstract = {Directed acyclic graph (DAG) models are popular tools for describing causal relationships and for guiding attempts to learn them from data.  They appear to supply a means of extracting causal concl...},
	language = {en},
	urldate = {2018-03-09},
	booktitle = {Causality: {Objectives} and {Assessment}},
	author = {Dawid, A. Philip},
	month = feb,
	year = {2010},
	pages = {59--86},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/K2FLIM3E/Dawid - 2010 - Beware of the DAG!.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/3BBKAGH9/dawid10a.html:text/html}
}

@article{peters_structural_2015,
	title = {Structural {Intervention} {Distance} for {Evaluating} {Causal} {Graphs}},
	volume = {27},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/NECO_a_00708},
	doi = {10.1162/NECO_a_00708},
	abstract = {Causal inference relies on the structure of a graph, often a directed acyclic graph (DAG). Different graphs may result in different causal inference statements and different intervention distributions. To quantify such differences, we propose a (pre-)metric between DAGs, the structural intervention distance (SID). The SID is based on a graphical criterion only and quantifies the closeness between two DAGs in terms of their corresponding causal inference statements. It is therefore well suited for evaluating graphs that are used for computing interventions. Instead of DAGs, it is also possible to compare CPDAGs, completed partially DAGs that represent Markov equivalence classes. The SID differs significantly from the widely used structural Hamming distance and therefore constitutes a valuable additional measure. We discuss properties of this distance and provide a (reasonably) efficient implementation with software code available on the first author’s home page.},
	number = {3},
	urldate = {2019-03-19},
	journal = {Neural Computation},
	author = {Peters, Jonas and Bühlmann, Peter},
	month = jan,
	year = {2015},
	pages = {771--799}
}

@book{vapnik_nature_2013,
	title = {The {Nature} of {Statistical} {Learning} {Theory}},
	isbn = {978-1-4757-3264-1},
	abstract = {The aim of this book is to discuss the fundamental ideas which lie behind the statistical theory of learning and generalization. It considers learning as a general problem of function estimation based on empirical data. Omitting proofs and technical details, the author concentrates on discussing the main results of learning theory and their connections to fundamental problems in statistics. These include: * the setting of learning problems based on the model of minimizing the risk functional from empirical data * a comprehensive analysis of the empirical risk minimization principle including necessary and sufficient conditions for its consistency * non-asymptotic bounds for the risk achieved using the empirical risk minimization principle * principles for controlling the generalization ability of learning machines using small sample sizes based on these bounds * the Support Vector methods that control the generalization ability when estimating function using small sample size. The second edition of the book contains three new chapters devoted to further development of the learning theory and SVM techniques. These include: * the theory of direct method of learning based on solving multidimensional integral equations for density, conditional probability, and conditional density estimation * a new inductive principle of learning. Written in a readable and concise style, the book is intended for statisticians, mathematicians, physicists, and computer scientists. Vladimir N. Vapnik is Technology Leader AT\&T Labs-Research and Professor of London University. He is one of the founders of statistical learning theory, and the author of seven books published in English, Russian, German, and Chinese.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Vapnik, Vladimir},
	month = jun,
	year = {2013},
	note = {Google-Books-ID: EqgACAAAQBAJ},
	keywords = {Computers / Intelligence (AI) \& Semantics, Mathematics / Probability \& Statistics / General, Science / General}
}


@techreport{gordon_comparison_2018,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {A {Comparison} of {Approaches} to {Advertising} {Measurement}: {Evidence} from {Big} {Field} {Experiments} at {Facebook}},
	shorttitle = {A {Comparison} of {Approaches} to {Advertising} {Measurement}},
	url = {https://papers.ssrn.com/abstract=3033144},
	abstract = {Measuring the causal effects of digital advertising remains challenging despite the availability of granular data. Unobservable factors make exposure endogenous, and advertising’s effect on outcomes tends to be small. In principle, these concerns could be addressed using randomized controlled trials (RCTs). In practice, few online ad campaigns rely on RCTs, and instead use observational methods to estimate ad effects. We assess empirically whether the variation in data typically available in the advertising industry enables observational methods to recover the causal effects of online advertising. Using data from 15 US advertising experiments at Facebook comprising 500 million user-experiment observations and 1.6 billion ad impressions, we contrast the experimental results to those obtained from multiple observational models. The observational methods often fail to produce the same effects as the randomized experiments, even after conditioning on extensive demographic and behavioral variables. In our setting, advances in causal inference methods do not allow us to isolate the exogenous variation needed to estimate the treatment effects. We also characterize the incremental explanatory power our data would require to enable observational methods to successfully measure advertising effects. Our findings suggest that commonly used observational approaches based on the data usually available in the industry often fail to accurately measure the true effect of advertising.},
	language = {en},
	number = {ID 3033144},
	urldate = {2019-02-07},
	institution = {Social Science Research Network},
	author = {Gordon, Brett R. and Zettelmeyer, Florian and Bhargava, Neha and Chapsky, Dan},
	month = sep,
	year = {2018},
	keywords = {causal inference, advertising effects, digital advertising, field experiments, observational methods},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/BKFEMWA8/Gordon et al. - 2018 - A Comparison of Approaches to Advertising Measurem.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/NK2L98R6/papers.html:text/html}
}

@techreport{heckman_randomization_1991,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Randomization and {Social} {Policy} {Evaluation}},
	url = {https://papers.ssrn.com/abstract=995151},
	abstract = {This paper considers the recent case for randomized social experimentation and contrasts it with older cases for social experimentation. The recent case eschews behavioral models, assumes that certain mean differences in outcomes are the parameters of interest to evaluators and assumes that randomization does not disrupt the social program being analyzed. Conditions under which program disruption effects are of no consequence are presented. Even in the absence of randomization bias, ideal experimental data cannot estimate median (other quantile) differences between treated and untreated persons without invoking supplementary statistical assumptions. The recent case for randomized experimentation does not address the choice of the appropriate stage in a multistage program at which randomization should be conducted. Evidence on randomization bias is presented.},
	language = {en},
	number = {ID 995151},
	urldate = {2019-02-04},
	institution = {Social Science Research Network},
	author = {Heckman, James J.},
	month = jul,
	year = {1991},
	keywords = {James J. Heckman, Randomization and Social Policy Evaluation, SSRN},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/2J6VCTJD/Heckman - 1991 - Randomization and Social Policy Evaluation.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/NPXF69CD/papers.html:text/html}
}

@article{lemeire_replacing_2013,
	title = {Replacing {Causal} {Faithfulness} with {Algorithmic} {Independence} of {Conditionals}},
	volume = {23},
	issn = {0924-6495, 1572-8641},
	url = {https://link.springer.com/article/10.1007/s11023-012-9283-1},
	doi = {10.1007/s11023-012-9283-1},
	abstract = {Independence of Conditionals (IC) has recently been proposed as a basic rule for causal structure learning. If a Bayesian network represents the causal structure, its Conditional Probability Distributions (CPDs) should be algorithmically independent. In this paper we compare IC with causal faithfulness (FF), stating that only those conditional independences that are implied by the causal Markov condition hold true. The latter is a basic postulate in common approaches to causal structure learning. The common spirit of FF and IC is to reject causal graphs for which the joint distribution looks ‘non-generic’. The difference lies in the notion of genericity: FF sometimes rejects models just because one of the CPDs is simple, for instance if the CPD describes a deterministic relation. IC does not behave in this undesirable way. It only rejects a model when there is a non-generic relation between different CPDs although each CPD looks generic when considered separately. Moreover, it detects relations between CPDs that cannot be captured by conditional independences. IC therefore helps in distinguishing causal graphs that induce the same conditional independences (i.e., they belong to the same Markov equivalence class). The usual justification for FF implicitly assumes a prior that is a probability density on the parameter space. IC can be justified by Solomonoff’s universal prior, assigning non-zero probability to those points in parameter space that have a finite description. In this way, it favours simple CPDs, and therefore respects Occam’s razor. Since Kolmogorov complexity is uncomputable, IC is not directly applicable in practice. We argue that it is nevertheless helpful, since it has already served as inspiration and justification for novel causal inference algorithms.},
	language = {en},
	number = {2},
	urldate = {2018-05-24},
	journal = {Minds and Machines},
	author = {Lemeire, Jan and Janzing, Dominik},
	month = may,
	year = {2013},
	pages = {227--249},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/VSRYINKU/Lemeire and Janzing - 2013 - Replacing Causal Faithfulness with Algorithmic Ind.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/DCRU8TNB/s11023-012-9283-1.html:text/html}
}

@book{spirtes_causation_1993,
  title={Causation, prediction, and search},
  author={Spirtes, Peter and Glymour, Clark N and Scheines, Richard and Heckerman, David and Meek, Christopher and Cooper, Gregory and Richardson, Thomas},
  year={2000},
  publisher={MIT press}
}


@book{wald_statistical_1950,
	address = {Oxford, England},
	series = {Statistical decision functions},
	title = {Statistical decision functions},
	abstract = {In 5 chapters the general theory of statistical decision functions is presented. The decision problem is shown to be interpretable as a zero sum two-person game in von Neumann's theory. A generalization of this game type is basic to the development of the general theory. Chapter 4 considers the "case of a sequence of identically and independently distributed chance variables." Special illustrative problems are discussed in Chapter 5. 76-item bibliography. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {Wiley},
	author = {Wald, Abraham},
	year = {1950},
	file = {Snapshot:/home/users/u4533535/Zotero/storage/DAIIQKBL/1951-01400-000.html:text/html}
}

@article{richardson2013single,
  title={Single world intervention graphs (SWIGs): A unification of the counterfactual and graphical approaches to causality},
  author={Richardson, Thomas S and Robins, James M},
  journal={Center for the Statistics and the Social Sciences, University of Washington Series. Working Paper},
  volume={128},
  number={30},
  pages={2013},
  year={2013},
  publisher={Citeseer}
}

@article{ramsey_adjacency-faithfulness_2012,
	title = {Adjacency-{Faithfulness} and {Conservative} {Causal} {Inference}},
	url = {http://arxiv.org/abs/1206.6843},
	abstract = {Most causal inference algorithms in the literature (e.g., Pearl (2000), Spirtes et al. (2000), Heckerman et al. (1999)) exploit an assumption usually referred to as the causal Faithfulness or Stability condition. In this paper, we highlight two components of the condition used in constraint-based algorithms, which we call "Adjacency-Faithfulness" and "Orientation-Faithfulness". We point out that assuming Adjacency-Faithfulness is true, it is in principle possible to test the validity of Orientation-Faithfulness. Based on this observation, we explore the consequence of making only the Adjacency-Faithfulness assumption. We show that the familiar PC algorithm has to be modified to be (asymptotically) correct under the weaker, Adjacency-Faithfulness assumption. Roughly the modified algorithm, called Conservative PC (CPC), checks whether Orientation-Faithfulness holds in the orientation phase, and if not, avoids drawing certain causal conclusions the PC algorithm would draw. However, if the stronger, standard causal Faithfulness condition actually obtains, the CPC algorithm is shown to output the same pattern as the PC algorithm does in the large sample limit. We also present a simulation study showing that the CPC algorithm runs almost as fast as the PC algorithm, and outputs significantly fewer false causal arrowheads than the PC algorithm does on realistic sample sizes. We end our paper by discussing how score-based algorithms such as GES perform when the Adjacency-Faithfulness but not the standard causal Faithfulness condition holds, and how to extend our work to the FCI algorithm, which allows for the possibility of latent variables.},
	urldate = {2018-02-26},
	journal = {arXiv:1206.6843 [cs, stat]},
	author = {Ramsey, Joseph and Zhang, Jiji and Spirtes, Peter L.},
	month = jun,
	year = {2012},
	note = {arXiv: 1206.6843},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Methodology},
	annote = {Adaptation of PC algorithm that distinguishes between orientation-faithfulness and adjacency-faithfulness. Orientation faithfulness can be tested, as given an unshielded collider X-{\textgreater}Y{\textless}-Z, any set containing Y should render X indep Z, and any set not containing Y should render X dep Z.
 
Derives "conservative" PC algorithm that assumes only adjacency-faithfulness.},
	annote = {Comment: Appears in Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence (UAI2006)},
	file = {arXiv\:1206.6843 PDF:/home/users/u4533535/Zotero/storage/5J3TGVYR/Ramsey et al. - 2012 - Adjacency-Faithfulness and Conservative Causal Inf.pdf:application/pdf;arXiv.org Snapshot:/home/users/u4533535/Zotero/storage/8VWWK4MQ/1206.html:text/html}
}

@article{chickering_optimal_2003,
	title = {Optimal {Structure} {Identification} with {Greedy} {Search}},
	volume = {3},
	issn = {1532-4435},
	url = {https://doi.org/10.1162/153244303321897717},
	doi = {10.1162/153244303321897717},
	abstract = {In this paper we prove the so-called "Meek Conjecture". In particular, we show that if a DAG H is an independence map of another DAG G, then there exists a finite sequence of edge additions and covered edge reversals in G such that (1) after each edge modification H remains an independence map of G and (2) after all modifications G =H. As shown by Meek (1997), this result has an important consequence for Bayesian approaches to learning Bayesian networks from data: in the limit of large sample size, there exists a two-phase greedy search algorithm that---when applied to a particular sparsely-connected search space---provably identifies a perfect map of the generative distribution if that perfect map is a DAG. We provide a new implementation of the search space, using equivalence classes as states, for which all operators used in the greedy search can be scored efficiently using local functions of the nodes in the domain. Finally, using both synthetic and real-world datasets, we demonstrate that the two-phase greedy approach leads to good solutions when learning with finite sample sizes.},
	urldate = {2018-02-27},
	journal = {J. Mach. Learn. Res.},
	author = {Chickering, David Maxwell},
	month = mar,
	year = {2003},
	pages = {507--554},
	annote = {It's possible to identify the "true" data-generating DAG in the infinite sample limit using a two-phase local search algorithm. This follows from the fact that it's possible to},
	file = {ACM Full Text PDF:/home/users/u4533535/Zotero/storage/FIK5RCSU/Chickering - 2003 - Optimal Structure Identification with Greedy Searc.pdf:application/pdf}
}



@inproceedings{meek_strong_1995,
	address = {San Francisco, CA, USA},
	series = {{UAI}'95},
	title = {Strong {Completeness} and {Faithfulness} in {Bayesian} {Networks}},
	isbn = {978-1-55860-385-1},
	url = {http://dl.acm.org/citation.cfm?id=2074158.2074205},
	abstract = {A completeness result for d-separation applied to discrete Bayesian networks is presented and it is shown that in a strong measure-theoretic sense almost all discrete distributions for a given network structure are faithful; i.e. the independence facts true of the distribution are all and only those entailed by the network structure},
	urldate = {2019-03-19},
	booktitle = {Proceedings of the {Eleventh} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Meek, Christopher},
	year = {1995},
	note = {event-place: Montréal, Qué, Canada},
	pages = {411--418},
	file = {ACM Full Text PDF:/home/users/u4533535/Zotero/storage/Z7SLGEL6/Meek - 1995 - Strong Completeness and Faithfulness in Bayesian N.pdf:application/pdf}
}

@article{berkson_difficulties_1938,
	title = {Some {Difficulties} of {Interpretation} {Encountered} in the {Application} of the {Chi}-{Square} {Test}},
	volume = {33},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2279690},
	doi = {10.2307/2279690},
	number = {203},
	urldate = {2019-04-28},
	journal = {Journal of the American Statistical Association},
	author = {Berkson, Joseph},
	year = {1938},
	pages = {526--536}
}


@article{robins_uniform_2003,
	title = {Uniform consistency in causal inference},
	volume = {90},
	issn = {0006-3444},
	url = {https://academic.oup.com/biomet/article/90/3/491/231406},
	doi = {10.1093/biomet/90.3.491},
	abstract = {Abstract.  There is a long tradition of representing causal relationships by directed acyclic graphs (Wright, 1934). Spirtes (1994), Spirtes et al. (1993) and P},
	language = {en},
	number = {3},
	urldate = {2019-05-23},
	journal = {Biometrika},
	author = {Robins, James M. and Scheines, Richard and Spirtes, Peter and Wasserman, Larry},
	month = sep,
	year = {2003},
	pages = {491--515},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/B3JDBVAS/Robins et al. - 2003 - Uniform consistency in causal inference.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/V2Y4URMV/231406.html:text/html}
}


@inproceedings{zhang_strong_2003,
	address = {San Francisco, CA, USA},
	series = {{UAI}'03},
	title = {Strong {Faithfulness} and {Uniform} {Consistency} in {Causal} {Inference}},
	isbn = {978-0-12-705664-7},
	url = {http://dl.acm.org/citation.cfm?id=2100584.2100661},
	abstract = {A fundamental question in causal inference is whether it is possible to reliably infer manipulation effects from observational data. There are a variety of senses of asymptotic reliability in the statistical literature, among which the most commonly discussed frequentist notions are pointwise consistency and uniform consistency (see, e.g. Bickel, Doksum [2001]). Uniform consistency is in general preferred to pointwise consistency because the former allows us to control the worst case error bounds with a finite sample size. In the sense of pointwise consistency, several reliable causal inference algorithms have been constructed under the Markov and Faithfulness assumptions [Pearl 2000, Spirtes et al. 2001]. In the sense of uniform consistency, however, reliable causal inference is impossible under the two assumptions when time order is unknown and/or latent confounders are present [Robins et al. 20001. In this paper we present two natural generalizations of the Faithfulness assumption in the context of structural equation models, under which we show that the typical algorithms in the literature (in some cases with modifications) are uniformly consistent even when the time order is unknown. We also discuss the situation where latent confounders may be present and the sense in which the Faithfulness assumption is a limiting case of the stronger assumptions.},
	urldate = {2019-05-23},
	booktitle = {Proceedings of the {Nineteenth} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Zhang, Jiji and Spirtes, Peter},
	year = {2003},
	note = {event-place: Acapulco, Mexico},
	pages = {632--639},
	file = {ACM Full Text PDF:/home/users/u4533535/Zotero/storage/W5DV7HW2/Zhang and Spirtes - 2003 - Strong Faithfulness and Uniform Consistency in Cau.pdf:application/pdf}
}

@article{gelman_bayesian_2010,
	title = {Bayesian {Statistics} {Then} and {Now}},
	volume = {25},
	issn = {0883-4237, 2168-8745},
	url = {https://projecteuclid.org/euclid.ss/1290175837},
	doi = {10.1214/10-STS308B},
	abstract = {Project Euclid - mathematics and statistics online},
	language = {EN},
	number = {2},
	urldate = {2019-04-28},
	journal = {Statistical Science},
	author = {Gelman, Andrew},
	month = may,
	year = {2010},
	mrnumber = {MR2789985},
	zmnumber = {1328.62045},
	pages = {162--165},
	file = {Full Text PDF:C\:\\Users\\david\\Zotero\\storage\\838N6CI5\\Gelman - 2010 - Bayesian Statistics Then and Now.pdf:application/pdf;Snapshot:C\:\\Users\\david\\Zotero\\storage\\UAJBSM99\\1290175837.html:text/html}
}


@article{meehl_theory-testing_1967,
	title = {Theory-{Testing} in {Psychology} and {Physics}: {A} {Methodological} {Paradox}},
	volume = {34},
	issn = {0031-8248},
	shorttitle = {Theory-{Testing} in {Psychology} and {Physics}},
	url = {https://www.journals.uchicago.edu/doi/abs/10.1086/288135},
	doi = {10.1086/288135},
	abstract = {Because physical theories typically predict numerical values, an improvement in experimental precision reduces the tolerance range and hence increases corroborability. In most psychological research, improved power of a statistical design leads to a prior probability approaching 1/2 of finding a significant difference in the theoretically predicted direction. Hence the corroboration yielded by "success" is very weak, and becomes weaker with increased precision. "Statistical significance" plays a logical role in psychology precisely the reverse of its role in physics. This problem is worsened by certain unhealthy tendencies prevalent among psychologists, such as a premium placed on experimental "cuteness" and a free reliance upon ad hoc explanations to avoid refutation.},
	number = {2},
	urldate = {2019-04-28},
	journal = {Philosophy of Science},
	author = {Meehl, Paul E.},
	month = jun,
	year = {1967},
	pages = {103--115},
	file = {Snapshot:C\:\\Users\\david\\Zotero\\storage\\VX8BUWUP\\288135.html:text/html}
}




@article{zhang_intervention_2011,
	title = {Intervention, determinism, and the causal minimality condition},
	volume = {182},
	issn = {1573-0964},
	url = {https://doi.org/10.1007/s11229-010-9751-1},
	doi = {10.1007/s11229-010-9751-1},
	abstract = {We clarify the status of the so-called causal minimality condition in the theory of causal Bayesian networks, which has received much attention in the recent literature on the epistemology of causation. In doing so, we argue that the condition is well motivated in the interventionist (or manipulability) account of causation, assuming the causal Markov condition which is essential to the semantics of causal Bayesian networks. Our argument has two parts. First, we show that the causal minimality condition, rather than an add-on methodological assumption of simplicity, necessarily follows from the substantive interventionist theses, provided that the actual probability distribution is strictly positive. Second, we demonstrate that the causal minimality condition can fail when the actual probability distribution is not positive, as is the case in the presence of deterministic relationships. But we argue that the interventionist account still entails a pragmatic justification of the causal minimality condition. Our argument in the second part exemplifies a general perspective that we think commendable: when evaluating methods for inferring causal structures and their underlying assumptions, it is relevant to consider how the inferred causal structure will be subsequently used for counterfactual reasoning.},
	language = {en},
	number = {3},
	urldate = {2019-04-27},
	journal = {Synthese},
	author = {Zhang, Jiji and Spirtes, Peter},
	month = oct,
	year = {2011},
	keywords = {Causal Bayesian network, Causation, Determinism, Intervention, Markov condition, Probability},
	pages = {335--347},
	file = {Springer Full Text PDF:C\:\\Users\\david\\Zotero\\storage\\2UKEIU5U\\Zhang and Spirtes - 2011 - Intervention, determinism, and the causal minimali.pdf:application/pdf}
}


@Book{cinlar_probability_2011,
  author = {Erhan \c{C}inlar},
  title = {Probability and Stochastics},
  year = 2011,
  publisher = {Springer}
}



@book{pearl_causality:_2009,
	edition = {2},
	title = {Causality: {Models}, {Reasoning} and {Inference}},
	publisher = {Cambridge University Press},
	author = {Pearl, Judea},
	year = {2009}
}